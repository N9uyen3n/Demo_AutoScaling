{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14707778,"sourceType":"datasetVersion","datasetId":9396610}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ”¬ HYBRID PROPHET + LSTM AUTOMATED PIPELINE\n## Multi-Resolution Hybrid Forecasting with Auto-Benchmark\n\n### ðŸš€ AUTO-RUN CONFIGURATION:\n**Just click \"Run All\" and the notebook will automatically:**\n1. Train Hybrid models for ALL resolutions (1min, 5min, 15min)\n2. Forecast BOTH targets (request_count, total_bytes)\n3. Combine Prophet (trend + seasonality) with LSTM (residual patterns)\n4. Detect anomalies using dynamic thresholds\n5. Generate comprehensive benchmarks\n6. Compare Hybrid vs Pure Prophet vs Pure LSTM\n\n### ðŸ“Š Total Configurations:\n- **3 resolutions** Ã— **2 targets** = **6 hybrid models**\n- Each configuration trains 3 models: Prophet, LSTM, Hybrid\n- Expected runtime: **40-70 minutes** (with GPU)\n\n### ðŸ§¬ Hybrid Architecture:\n```\nProphet (Trend + Seasonality)\n    â†“\nResidual = Actual - Prophet_Forecast\n    â†“\nLSTM (Learn Residual Patterns)\n    â†“\nFinal = Prophet_Forecast + LSTM_Residual\n```\n\n### ðŸ“ Output Structure:\n```\nRESULTS_HYBRID/\nâ”œâ”€â”€ 1min_request_count/\nâ”‚   â”œâ”€â”€ prophet_model/ (forecast, components)\nâ”‚   â”œâ”€â”€ lstm_model.keras\nâ”‚   â”œâ”€â”€ scaler.pkl\nâ”‚   â”œâ”€â”€ hybrid_predictions.csv\nâ”‚   â”œâ”€â”€ anomalies.csv\nâ”‚   â”œâ”€â”€ metrics_comparison.csv (Prophet vs LSTM vs Hybrid)\nâ”‚   â””â”€â”€ visualizations.png\nâ”œâ”€â”€ ... (5 more configurations)\nâ””â”€â”€ FINAL_BENCHMARK/\n    â”œâ”€â”€ comprehensive_comparison.csv\n    â”œâ”€â”€ hybrid_vs_individual.csv\n    â”œâ”€â”€ final_report.txt\n    â””â”€â”€ benchmark_visualizations.png\n```","metadata":{}},{"cell_type":"code","source":"# ===========================\n# CELL 2: SETUP & INSTALLATIONS\n# ===========================\n\n!pip install prophet tensorflow scikit-learn -q\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom tensorflow.keras.layers import Attention, Input, Concatenate\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport pickle\nfrom datetime import datetime\nimport time\nfrom typing import Dict, List, Tuple\n\n# Prophet\nfrom prophet import Prophet\n\n# TensorFlow/Keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Set seeds\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Visualization\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette(\"husl\")\nplt.rcParams['figure.figsize'] = (18, 6)\n\nprint(\"=\"*70)\nprint(\"HYBRID PROPHET + LSTM AUTOMATED TRAINING PIPELINE\")\nprint(\"=\"*70)\nprint(f\"  TensorFlow version: {tf.__version__}\")\nprint(f\"  GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\nprint(f\"  Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:13:59.938423Z","iopub.execute_input":"2026-02-02T13:13:59.939037Z","iopub.status.idle":"2026-02-02T13:14:03.443403Z","shell.execute_reply.started":"2026-02-02T13:13:59.939013Z","shell.execute_reply":"2026-02-02T13:14:03.442638Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nHYBRID PROPHET + LSTM AUTOMATED TRAINING PIPELINE\n======================================================================\n  TensorFlow version: 2.19.0\n  GPU available: True\n  Start time: 2026-02-02 13:14:03\n======================================================================\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# ===========================\n# CELL 3: GLOBAL CONFIGURATION\n# ===========================\n\n# Paths\nDATA_DIR = '/kaggle/input/nasa-1/PROCESSED_DATAFINAL'\nRESULTS_BASE_DIR = '/kaggle/working/'\n\n# Create base results directory\nos.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n\n# All configurations to run\nRESOLUTIONS = ['5min', '15min']\nTARGETS = ['request_count', 'total_bytes']\n\n# Resolution-specific parameters\nRESOLUTION_PARAMS = {\n    '5min': {\n        'window': 10,        \n        'lstm_units': 50,\n        'epochs': 50,\n        'batch_size': 50\n    },\n    '15min': {\n        'window': 5,          \n        'lstm_units': 50,\n        'epochs': 50,\n        'batch_size': 50 \n    }\n}\n\n# Prophet parameters\nPROPHET_PARAMS = {\n    'daily_seasonality': False,\n    'weekly_seasonality': False,\n    'yearly_seasonality': False,\n    'changepoint_prior_scale': 5,\n    'seasonality_prior_scale': 30,\n    'seasonality_mode': 'multiplicative'\n}\n\n# Storm/outage holiday\nSTORM_HOLIDAY = pd.DataFrame({\n    'holiday': 'storm_outage',\n    'ds': pd.date_range(start='1995-08-01 14:52:01', end='1995-08-03 04:36:13', freq='h'),\n    'lower_window': 0,\n    'upper_window': 0,\n})\n\nprint(\"\\nðŸ“‹ CONFIGURATION LOADED:\")\nprint(f\"  Resolutions: {RESOLUTIONS}\")\nprint(f\"  Targets: {TARGETS}\")\nprint(f\"  Total configurations: {len(RESOLUTIONS) * len(TARGETS)}\")\nprint(f\"\\n  Data directory: {DATA_DIR}\")\nprint(f\"  Results directory: {RESULTS_BASE_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:14:03.445005Z","iopub.execute_input":"2026-02-02T13:14:03.445228Z","iopub.status.idle":"2026-02-02T13:14:03.454606Z","shell.execute_reply.started":"2026-02-02T13:14:03.445206Z","shell.execute_reply":"2026-02-02T13:14:03.453937Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“‹ CONFIGURATION LOADED:\n  Resolutions: ['5min', '15min']\n  Targets: ['request_count', 'total_bytes']\n  Total configurations: 4\n\n  Data directory: /kaggle/input/nasa-1/PROCESSED_DATAFINAL\n  Results directory: /kaggle/working/\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# ===========================\n# CELL 4: UTILITY FUNCTIONS\n# ===========================\n\ndef prepare_prophet_data(df, target_col):\n    \"\"\"\n    Prepare data for Prophet.\n    \"\"\"\n    prophet_df = pd.DataFrame({\n        'ds': df.index,\n        'y': df[target_col]\n    })\n    \n    # Add time-based features\n    prophet_df['hour'] = prophet_df['ds'].dt.hour\n    prophet_df['day_of_week'] = prophet_df['ds'].dt.dayofweek\n    prophet_df['is_weekend'] = (prophet_df['day_of_week'] >= 5).astype(int)\n    \n    return prophet_df\n\n\ndef make_sequences(data, window):\n    \"\"\"\n    Create sequences for LSTM.\n    \"\"\"\n    X, y = [], []\n    for i in range(window, len(data)):\n        X.append(data[i-window:i])\n        y.append(data[i])\n    return np.array(X), np.array(y)\n\ndef create_multivariate_features(df, train_size, window):\n    \"\"\"\n    Táº¡o bá»™ dá»¯ liá»‡u Ä‘a chiá»u cho LSTM:\n    1. Residual (Scaled)\n    2. Prophet Prediction (Scaled) - Äá»ƒ há»c Ä‘á»™ lá»›n\n    3. Hour Sin/Cos - Äá»ƒ há»c tÃ­nh chu ká»³ thá»i gian\n    \"\"\"\n    # 1. Feature: Residual\n    resid_values = df[['residual']].values\n    scaler_resid = StandardScaler()\n    # Chá»‰ fit trÃªn táº­p train\n    scaler_resid.fit(resid_values[:train_size]) \n    resid_scaled = scaler_resid.transform(resid_values)\n    \n    # 2. Feature: Context (Prophet Prediction)\n    yhat_values = df[['yhat_prophet']].values\n    scaler_context = StandardScaler()\n    scaler_context.fit(yhat_values[:train_size])\n    yhat_scaled = scaler_context.transform(yhat_values)\n    \n    # 3. Feature: Time Cyclical Encoding\n    # Biáº¿n Ä‘á»•i giá» thÃ nh vÃ²ng trÃ²n (23h gáº§n 0h)\n    hour_sin = np.sin(2 * np.pi * df.index.hour / 24).values.reshape(-1, 1)\n    hour_cos = np.cos(2 * np.pi * df.index.hour / 24).values.reshape(-1, 1)\n    \n    # Gá»™p táº¥t cáº£ features: Shape (N, 4)\n    # [Residual, Prophet_Hat, Hour_Sin, Hour_Cos]\n    features_matrix = np.hstack([resid_scaled, yhat_scaled, hour_sin, hour_cos])\n    \n    return features_matrix, scaler_resid\n\ndef make_multivariate_sequences(features, targets, window):\n    \"\"\"\n    X: Multivariate features (t-window ... t-1)\n    y: Target residual (t)\n    \"\"\"\n    X, y = [], []\n    for i in range(window, len(features)):\n        X.append(features[i-window:i, :]) # Láº¥y cá»­a sá»• cá»§a Táº¤T Cáº¢ features\n        y.append(targets[i])             # Chá»‰ dá»± Ä‘oÃ¡n residual (Ä‘Ã£ scale)\n    return np.array(X), np.array(y)\n\n\ndef calculate_metrics(y_true, y_pred, model_name=\"Model\"):\n    \"\"\"\n    Calculate comprehensive metrics.\n    \"\"\"\n    mae = mean_absolute_error(y_true, y_pred)\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    \n    # MAPE (avoid division by zero)\n    mask = y_true != 0\n    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else 0\n    \n    # RÂ²\n    r2 = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_true.mean())**2))\n    \n    metrics = {\n        'Model': model_name,\n        'MAE': mae,\n        'MSE': mse,\n        'RMSE': rmse,\n        'MAPE': mape,\n        'R2': r2\n    }\n    \n    return metrics\n\n\ndef detect_anomalies(y_true, y_pred, window_size, threshold=3):\n    \"\"\"\n    Detect anomalies using dynamic Z-score on prediction error.\n    \"\"\"\n    error = np.abs(y_true - y_pred)\n    \n    # Rolling statistics\n    rolling_mean = pd.Series(error).rolling(window_size, min_periods=1).mean()\n    rolling_std = pd.Series(error).rolling(window_size, min_periods=1).std()\n    \n    # Z-score\n    z_score = (error - rolling_mean) / (rolling_std + 1e-8)\n    \n    # Anomaly indices\n    anomaly_mask = z_score > threshold\n    anomaly_indices = np.where(anomaly_mask)[0]\n    \n    return anomaly_indices, z_score.values\n\n\nprint(\"âœ“ Utility functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:14:03.455664Z","iopub.execute_input":"2026-02-02T13:14:03.455966Z","iopub.status.idle":"2026-02-02T13:14:03.478478Z","shell.execute_reply.started":"2026-02-02T13:14:03.455935Z","shell.execute_reply":"2026-02-02T13:14:03.477832Z"}},"outputs":[{"name":"stdout","text":"âœ“ Utility functions defined\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# # ===========================================================================================\n# # CELL 5: MAIN HYBRID TRAINING FUNCTION (FINAL VERSION: LOG + STORM MASKING)\n# # ===========================================================================================\n# from sklearn.preprocessing import MinMaxScaler\n# from keras.layers import Bidirectional, LSTM, Dense, Dropout\n# from keras.models import Sequential\n# from keras.losses import Huber\n# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# from prophet import Prophet\n# import numpy as np\n# import pandas as pd\n# import os\n# import time\n# import pickle\n\n# def train_hybrid_model(resolution, target, verbose=True):\n#     \"\"\"\n#     Train Hybrid Prophet + LSTM model with:\n#     1. Storm Masking (NaN for outage periods)\n#     2. Input Log Transformation (Amplitude Correction)\n#     3. Robust LSTM Architecture (Bidirectional + Huber Loss)\n#     \"\"\"\n#     if verbose:\n#         print(f\"\\n{'='*70}\")\n#         print(f\"TRAINING: Hybrid (Log + Storm-Masked) | {resolution} | {target}\")\n#         print(f\"{'='*70}\")\n    \n#     start_time = time.time()\n    \n#     # --- Cáº¤U HÃŒNH ---\n#     # Láº¥y params tá»« dict global hoáº·c hardcode náº¿u cáº§n\n#     params = RESOLUTION_PARAMS[resolution]\n#     window = params['window']\n#     lstm_units = params['lstm_units']\n#     epochs = params['epochs']\n#     batch_size = params['batch_size']\n    \n#     results_dir = f\"{RESULTS_BASE_DIR}/{resolution}_{target}_final\"\n#     os.makedirs(results_dir, exist_ok=True)\n#     os.makedirs(f\"{results_dir}/prophet_model\", exist_ok=True)\n    \n#     try:\n#         # ==================\n#         # 1. LOAD DATA & STORM MASKING\n#         # ==================\n#         if verbose: print(f\"[1/7] Loading data & Masking Storm...\")\n        \n#         train_df = pd.read_csv(f\"{DATA_DIR}/train_{resolution}.csv\", index_col=0, parse_dates=True)\n#         test_df = pd.read_csv(f\"{DATA_DIR}/test_{resolution}.csv\", index_col=0, parse_dates=True)\n        \n#         # LÆ°u giÃ¡ trá»‹ thá»±c gá»‘c (Raw scale) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sau cÃ¹ng\n#         y_test_raw_true = test_df[target].values\n\n#         # --- [NEW] Xá»¬ LÃ BÃƒO (GÃ¡n NaN) ---\n#         # BÃ£o: 14:52:01 01/08/1995 -> 04:36:13 03/08/1995\n#         # Chá»‰ xá»­ lÃ½ trÃªn Train set vÃ¬ bÃ£o náº±m trong thÃ¡ng 8\n#         storm_start = pd.Timestamp(\"1995-08-01 14:52:01\")\n#         storm_end   = pd.Timestamp(\"1995-08-03 04:36:13\")\n        \n#         mask = (train_df.index >= storm_start) & (train_df.index <= storm_end)\n#         train_df.loc[mask, target] = None # GÃ¡n NaN Ä‘á»ƒ Prophet bá» qua\n        \n#         if verbose: print(f\"   -> Masked {mask.sum()} intervals as NaN due to storm.\")\n\n#         # --- LOG TRANSFORMATION ---\n#         # np.log1p xá»­ lÃ½ tá»‘t NaN (váº«n giá»¯ lÃ  NaN)\n#         train_df[target] = np.log1p(train_df[target])\n#         test_df[target] = np.log1p(test_df[target])\n        \n#         full_df = pd.concat([train_df, test_df]).sort_index()\n#         train_size = len(train_df)\n        \n#         # ==================\n#         # 2. TRAIN PROPHET (LOG SPACE)\n#         # ==================\n#         if verbose: print(f\"\\n[2/7] Training Prophet on Log Data...\")\n        \n#         prophet_train = prepare_prophet_data(train_df, target)\n        \n#         prophet_model = Prophet(\n#             changepoint_prior_scale=5.1, \n#             seasonality_prior_scale=30,\n#             seasonality_mode='additive', # Log space -> Additive\n#         )\n        \n#         # Seasonality (Khá»›p bÃ i bÃ¡o)\n#         prophet_model.add_seasonality(name='daily_high_freq', period=1, fourier_order=50)\n#         prophet_model.add_seasonality(name='weekly_high_freq', period=7, fourier_order=20)\n        \n#         prophet_model.add_regressor('hour')\n#         prophet_model.add_regressor('day_of_week')\n#         prophet_model.add_regressor('is_weekend')\n        \n#         prophet_model.fit(prophet_train)\n        \n#         # Forecast\n#         prophet_full = prepare_prophet_data(full_df, target)\n#         prophet_forecast = prophet_model.predict(prophet_full[['ds', 'hour', 'day_of_week', 'is_weekend']])\n        \n#         # ==================\n#         # 3. COMPUTE RESIDUALS\n#         # ==================\n#         full_df['yhat_prophet'] = prophet_forecast['yhat'].values\n#         full_df['residual'] = full_df[target] - full_df['yhat_prophet']\n        \n#         # --- [NEW] FILLNA FOR RESIDUALS ---\n#         # Táº¡i vÃ¹ng bÃ£o, target=NaN nÃªn residual=NaN. LSTM khÃ´ng hiá»ƒu NaN.\n#         # Ta fill 0 (coi nhÆ° Prophet dá»± Ä‘oÃ¡n Ä‘Ãºng xu hÆ°á»›ng, khÃ´ng cÃ³ lá»—i dÆ° thá»«a)\n#         full_df['residual'] = full_df['residual'].fillna(0)\n        \n#         if verbose: print(f\" Residual std (log-space): {full_df['residual'].std():.3f}\")\n        \n#         # ==================\n#         # 4. PREPARE LSTM DATA\n#         # ==================\n#         scaler = MinMaxScaler(feature_range=(0, 1))\n        \n#         residual_train_values = full_df.iloc[:train_size][['residual']].values\n#         scaler.fit(residual_train_values)\n#         residual_train_scaled = scaler.transform(residual_train_values)\n        \n#         X_train, y_train = make_sequences(residual_train_scaled.flatten(), window)\n#         X_train = X_train.reshape(-1, window, 1)\n        \n#         # Split Valid\n#         val_ratio = 0.2\n#         val_size = int(len(X_train) * val_ratio)\n#         X_train_sub = X_train[:-val_size]\n#         y_train_sub = y_train[:-val_size]\n#         X_val = X_train[-val_size:]\n#         y_val = y_train[-val_size:]\n        \n#         # ==================\n#         # 5. TRAIN LSTM (ROBUST ARCHITECTURE)\n#         # ==================\n#         if verbose: print(f\"\\n[5/7] Training Robust LSTM...\")\n        \n#         lstm_model = Sequential([\n#             Bidirectional(LSTM(lstm_units, return_sequences=True, input_shape=(window, 1))),\n#             Bidirectional(LSTM(lstm_units, return_sequences=False)),\n#             Dropout(0.2),\n#             Dense(1)\n#         ])\n        \n#         lstm_model.compile(optimizer='adam', loss=Huber(delta=1.0), metrics=['mae'])\n        \n#         callbacks = [\n#             EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss', verbose=1),\n#             ReduceLROnPlateau(patience=5, factor=0.5, monitor='val_loss', verbose=1)\n#         ]\n        \n#         history = lstm_model.fit(\n#             X_train_sub, y_train_sub,\n#             validation_data=(X_val, y_val),\n#             epochs=epochs,\n#             batch_size=batch_size,\n#             callbacks=callbacks,\n#             verbose=1\n#         )\n        \n#         # ==================\n#         # 6. HYBRID PREDICTION\n#         # ==================\n#         if verbose: print(f\"\\n[6/7] Generating hybrid predictions...\")\n        \n#         # Predict Residuals (All data)\n#         residual_all_values = full_df[['residual']].values\n#         residual_all_scaled = scaler.transform(residual_all_values)\n        \n#         X_all, _ = make_sequences(residual_all_scaled.flatten(), window)\n#         X_all = X_all.reshape(-1, window, 1)\n        \n#         residual_pred_scaled = lstm_model.predict(X_all, verbose=0)\n#         residual_pred_log = scaler.inverse_transform(residual_pred_scaled).flatten()\n        \n#         # Reconstruct Hybrid (Log Space)\n#         prophet_pred_log = full_df['yhat_prophet'].iloc[window:].values\n#         hybrid_pred_log = prophet_pred_log + residual_pred_log\n        \n#         # Inverse Transform (Log -> Real)\n#         hybrid_pred_final = np.expm1(hybrid_pred_log)\n#         prophet_pred_final = np.expm1(prophet_pred_log)\n        \n#         # ==================\n#         # 7. EVALUATION\n#         # ==================\n#         if verbose: print(f\"\\n[7/7] Evaluating models...\")\n\n#         # Cáº¯t dá»¯ liá»‡u Test\n#         lstm_test_start_idx = train_size - window\n        \n#         hybrid_test_pred = hybrid_pred_final[lstm_test_start_idx:]\n#         prophet_test_pred = prophet_pred_final[lstm_test_start_idx:]\n#         residual_test_pred = residual_pred_log[lstm_test_start_idx:] \n\n#         # Láº¥y dá»¯ liá»‡u thá»±c táº¿ (Láº¥y tá»« Log Residuals Ä‘á»ƒ so sÃ¡nh LSTM)\n#         residual_test_true = full_df['residual'].iloc[train_size:].values\n        \n#         # Äá»“ng bá»™ Ä‘á»™ dÃ i\n#         min_len = min(len(y_test_raw_true), len(hybrid_test_pred), len(residual_test_true))\n        \n#         y_test_true = y_test_raw_true[:min_len]\n#         hybrid_test_pred = hybrid_test_pred[:min_len]\n#         prophet_test_pred = prophet_test_pred[:min_len]\n#         residual_test_true = residual_test_true[:min_len]\n#         residual_test_pred = residual_test_pred[:min_len]\n        \n#         # Metrics\n#         prophet_metrics = calculate_metrics(y_test_true, prophet_test_pred, \"Prophet\")\n#         hybrid_metrics = calculate_metrics(y_test_true, hybrid_test_pred, \"Hybrid\")\n#         lstm_metrics = calculate_metrics(residual_test_true, residual_test_pred, \"LSTM_Residuals\")\n        \n#         residual_mape = np.mean(\n#             np.abs((residual_test_true - residual_test_pred) / (np.abs(residual_test_true) + 1e-8))\n#         ) * 100\n        \n#         if verbose:\n#             print(f\"\\n>>> LSTM Residuals MAPE on test: {residual_mape:.2f}% <<<\")\n#             print(\n#                 f\" Prophet - MAE: {prophet_metrics['MAE']:.2f}, \"\n#                 f\"MSE: {prophet_metrics['MSE']:.2f}, \"\n#                 f\"MAPE: {prophet_metrics['MAPE']:.2f}%, \"\n#                 f\"RMSE: {prophet_metrics['RMSE']:.2f}\"\n#             )\n#             # print(\n#             #     f\" LSTM Residuals - MAE: {lstm_metrics['MAE']:.2f}, \"\n#             #     f\"MSE: {lstm_metrics['MSE']:.2f}, \"\n#             #     f\"MAPE: {lstm_metrics['MAPE']:.2f}%, \"\n#             #     f\"RMSE: {lstm_metrics['RMSE']:.2f}\"\n#             # )\n#             print(\n#                 f\" Hybrid - MAE: {hybrid_metrics['MAE']:.2f}, \"\n#                 f\"MSE: {hybrid_metrics['MSE']:.2f}, \"\n#                 f\"MAPE: {hybrid_metrics['MAPE']:.2f}%, \"\n#                 f\"RMSE: {hybrid_metrics['RMSE']:.2f}\"\n#             )\n        \n#         # Save results (Giá»¯ nguyÃªn code save cá»§a báº¡n)\n#         elapsed_time = time.time() - start_time\n#         return {\n#             'resolution': resolution,\n#             'target': target,\n#             'prophet_mae': prophet_metrics['MAE'],\n#             'prophet_rmse': prophet_metrics['RMSE'],\n#             'prophet_mse': prophet_metrics['MSE'],\n#             'prophet_mape': prophet_metrics['MAPE'],\n#             'lstm_mae': lstm_metrics['MAE'],\n#             'lstm_rmse': lstm_metrics['RMSE'],\n#             'lstm_mse': lstm_metrics['MSE'],\n#             'lstm_mape': lstm_metrics['MAPE'],\n#             'hybrid_mae': hybrid_metrics['MAE'],\n#             'hybrid_rmse': hybrid_metrics['RMSE'],\n#             'hybrid_mse': hybrid_metrics['MSE'],\n#             'hybrid_mape': hybrid_metrics['MAPE'],\n#             'hybrid_r2': hybrid_metrics['R2'],\n#             'residual_mape_test': residual_mape,\n#             'training_time_sec': elapsed_time,\n#             'results_dir': results_dir\n#         }\n\n#     except Exception as e:\n#         print(f\"\\nâŒ ERROR: {str(e)}\")\n#         import traceback\n#         traceback.print_exc()\n#         return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:14:03.480436Z","iopub.execute_input":"2026-02-02T13:14:03.480684Z","iopub.status.idle":"2026-02-02T13:14:03.502436Z","shell.execute_reply.started":"2026-02-02T13:14:03.480663Z","shell.execute_reply":"2026-02-02T13:14:03.501731Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# # ===========================================================================================\n# # CELL 5: MAIN HYBRID TRAINING FUNCTION (NO LOG TRANSFORM VERSION)\n# # ===========================================================================================\n# from sklearn.preprocessing import MinMaxScaler\n# from keras.layers import Bidirectional, LSTM, Dense, Dropout\n# from keras.models import Sequential\n# from keras.losses import Huber\n# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# from prophet import Prophet\n# import numpy as np\n# import pandas as pd\n# import os\n# import time\n# import pickle\n\n# def train_hybrid_model(resolution, target, verbose=True):\n#     \"\"\"\n#     Train Hybrid Prophet + LSTM model WITHOUT Log Transformation.\n#     Running on RAW DATA.\n#     \"\"\"\n#     if verbose:\n#         print(f\"\\n{'='*70}\")\n#         print(f\"TRAINING: Hybrid (RAW DATA + Storm-Masked) | {resolution} | {target}\")\n#         print(f\"{'='*70}\")\n    \n#     start_time = time.time()\n    \n#     # --- Cáº¤U HÃŒNH ---\n#     # Láº¥y params tá»« dict global hoáº·c hardcode\n#     try:\n#         params = RESOLUTION_PARAMS[resolution]\n#     except:\n#         # Fallback náº¿u chÆ°a define dict\n#         params = {'window': 10, 'lstm_units': 50, 'epochs': 50, 'batch_size': 16}\n        \n#     window = params['window']\n#     lstm_units = params['lstm_units']\n#     epochs = params['epochs']\n#     batch_size = params['batch_size']\n    \n#     results_dir = f\"{RESULTS_BASE_DIR}/{resolution}_{target}_raw_no_log\"\n#     os.makedirs(results_dir, exist_ok=True)\n#     os.makedirs(f\"{results_dir}/prophet_model\", exist_ok=True)\n    \n#     try:\n#         # ==================\n#         # 1. LOAD DATA & STORM MASKING\n#         # ==================\n#         if verbose: print(f\"[1/7] Loading data & Masking Storm (Raw Data)...\")\n        \n#         train_df = pd.read_csv(f\"{DATA_DIR}/train_{resolution}.csv\", index_col=0, parse_dates=True)\n#         test_df = pd.read_csv(f\"{DATA_DIR}/test_{resolution}.csv\", index_col=0, parse_dates=True)\n        \n#         # LÆ°u giÃ¡ trá»‹ thá»±c gá»‘c Ä‘á»ƒ Ä‘Ã¡nh giÃ¡\n#         y_test_raw_true = test_df[target].values\n\n#         # --- Xá»¬ LÃ BÃƒO (GÃ¡n NaN) ---\n#         storm_start = pd.Timestamp(\"1995-08-01 14:52:01\")\n#         storm_end   = pd.Timestamp(\"1995-08-03 04:36:13\")\n        \n#         mask = (train_df.index >= storm_start) & (train_df.index <= storm_end)\n#         train_df.loc[mask, target] = None # GÃ¡n NaN\n        \n#         if verbose: print(f\"   -> Masked {mask.sum()} intervals as NaN due to storm.\")\n\n#         # --- [REMOVED] LOG TRANSFORMATION ---\n        \n#         full_df = pd.concat([train_df, test_df]).sort_index()\n#         train_size = len(train_df)\n        \n#         # ==================\n#         # 2. TRAIN PROPHET (RAW SPACE)\n#         # ==================\n#         if verbose: print(f\"\\n[2/7] Training Prophet on Raw Data...\")\n        \n#         prophet_train = prepare_prophet_data(train_df, target)\n        \n#         prophet_model = Prophet(\n#             changepoint_prior_scale=5, \n#             seasonality_prior_scale=30,\n#             # LÆ°u Ã½: Vá»›i dá»¯ liá»‡u Raw biáº¿n Ä‘á»™ng máº¡nh, 'multiplicative' thÆ°á»ng tá»‘t hÆ¡n 'additive'.\n#             # Tuy nhiÃªn Ä‘á»ƒ cháº¡y an toÃ n vá»›i sá»‘ 0, ta giá»¯ 'additive' hoáº·c cáº§n xá»­ lÃ½ sá»‘ 0 náº¿u dÃ¹ng 'multiplicative'.\n#             # á»ž Ä‘Ã¢y giá»¯ nguyÃªn 'additive' Ä‘á»ƒ so sÃ¡nh cÃ´ng báº±ng vá»›i báº£n Log.\n#             seasonality_mode='multiplicative', \n#         )\n        \n#         # Seasonality\n#         prophet_model.add_seasonality(name='daily_high_freq', period=1, fourier_order=50)\n#         prophet_model.add_seasonality(name='weekly_high_freq', period=7, fourier_order=20)\n        \n#         prophet_model.add_regressor('hour')\n#         prophet_model.add_regressor('day_of_week')\n#         prophet_model.add_regressor('is_weekend')\n        \n#         prophet_model.fit(prophet_train)\n        \n#         # Forecast\n#         prophet_full = prepare_prophet_data(full_df, target)\n#         prophet_forecast = prophet_model.predict(prophet_full[['ds', 'hour', 'day_of_week', 'is_weekend']])\n        \n#         # ==================\n#         # 3. COMPUTE RESIDUALS (RAW SPACE)\n#         # ==================\n#         full_df['yhat_prophet'] = prophet_forecast['yhat'].values\n        \n#         # Residual = Actual - Predicted (KhÃ´ng pháº£i Log - Log ná»¯a)\n#         full_df['residual'] = full_df[target] - full_df['yhat_prophet']\n        \n#         # Fill NaN residuals báº±ng 0 (cho vÃ¹ng bÃ£o)\n#         full_df['residual'] = full_df['residual'].fillna(0)\n        \n#         if verbose: \n#             print(f\" Residual std (raw-space): {full_df['residual'].std():.3f}\")\n#             # In ra max residual Ä‘á»ƒ tháº¥y sá»± khÃ¡c biá»‡t vá»›i báº£n Log\n#             print(f\" Max Residual: {full_df['residual'].max():.3f}\")\n        \n#         # ==================\n#         # 4. PREPARE LSTM DATA\n#         # ==================\n#         # MinMaxScaler cá»±c ká»³ quan trá»ng á»Ÿ Ä‘Ã¢y vÃ¬ biÃªn Ä‘á»™ dá»¯ liá»‡u Raw ráº¥t lá»›n\n#         scaler = MinMaxScaler(feature_range=(-1, 1))\n        \n#         residual_train_values = full_df.iloc[:train_size][['residual']].values\n#         scaler.fit(residual_train_values)\n#         residual_train_scaled = scaler.transform(residual_train_values)\n        \n#         X_train, y_train = make_sequences(residual_train_scaled.flatten(), window)\n#         X_train = X_train.reshape(-1, window, 1)\n        \n#         # Split Valid\n#         val_ratio = 0.1\n#         val_size = int(len(X_train) * val_ratio)\n#         X_train_sub = X_train[:-val_size]\n#         y_train_sub = y_train[:-val_size]\n#         X_val = X_train[-val_size:]\n#         y_val = y_train[-val_size:]\n        \n#         # ==================\n#         # 5. TRAIN LSTM\n#         # ==================\n#         if verbose: print(f\"\\n[5/7] Training Robust LSTM...\")\n        \n#         lstm_model = Sequential([\n#             Bidirectional(LSTM(lstm_units, return_sequences=True, input_shape=(window, 1))),\n#             Bidirectional(LSTM(lstm_units - 30, return_sequences=False)),\n#             Dropout(0.2),\n#             Dense(1)\n#         ])\n        \n#         lstm_model.compile(optimizer='adam', loss=Huber(delta=1.0), metrics=['mae'])\n        \n#         callbacks = [\n#             EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss', verbose=1),\n#             ReduceLROnPlateau(patience=5, factor=0.5, monitor='val_loss', verbose=1)\n#         ]\n        \n#         history = lstm_model.fit(\n#             X_train_sub, y_train_sub,\n#             validation_data=(X_val, y_val),\n#             epochs=epochs,\n#             batch_size=batch_size,\n#             callbacks=callbacks,\n#             verbose=1\n#         )\n        \n#         # ==================\n#         # 6. HYBRID PREDICTION\n#         # ==================\n#         if verbose: print(f\"\\n[6/7] Generating hybrid predictions...\")\n        \n#         # Predict Residuals (All data)\n#         residual_all_values = full_df[['residual']].values\n#         residual_all_scaled = scaler.transform(residual_all_values)\n        \n#         X_all, _ = make_sequences(residual_all_scaled.flatten(), window)\n#         X_all = X_all.reshape(-1, window, 1)\n        \n#         residual_pred_scaled = lstm_model.predict(X_all, verbose=0)\n#         # ÄÃ¢y lÃ  Residual dá»± bÃ¡o á»Ÿ dáº¡ng RAW (Ä‘Ã£ inverse scale)\n#         residual_pred_raw = scaler.inverse_transform(residual_pred_scaled).flatten()\n        \n#         # Reconstruct Hybrid (Raw Space)\n#         # Hybrid = Prophet + Residual\n#         prophet_pred_raw = full_df['yhat_prophet'].iloc[window:].values\n#         hybrid_pred_raw = prophet_pred_raw + residual_pred_raw\n        \n#         # --- [REMOVED] INVERSE TRANSFORM ---\n#         # KhÃ´ng cáº§n np.expm1 vÃ¬ dá»¯ liá»‡u Ä‘Ã£ lÃ  raw\n#         hybrid_pred_final = hybrid_pred_raw\n#         prophet_pred_final = prophet_pred_raw\n        \n#         # ==================\n#         # 7. EVALUATION\n#         # ==================\n#         if verbose: print(f\"\\n[7/7] Evaluating models...\")\n\n#         # Cáº¯t dá»¯ liá»‡u Test\n#         lstm_test_start_idx = train_size - window\n        \n#         hybrid_test_pred = hybrid_pred_final[lstm_test_start_idx:]\n#         prophet_test_pred = prophet_pred_final[lstm_test_start_idx:]\n#         residual_test_pred = residual_pred_raw[lstm_test_start_idx:] \n\n#         # Láº¥y Residual thá»±c táº¿ (Raw Space)\n#         residual_test_true = full_df['residual'].iloc[train_size:].values\n        \n#         # Äá»“ng bá»™ Ä‘á»™ dÃ i\n#         min_len = min(len(y_test_raw_true), len(hybrid_test_pred), len(residual_test_true))\n        \n#         y_test_true = y_test_raw_true[:min_len]\n#         hybrid_test_pred = hybrid_test_pred[:min_len]\n#         prophet_test_pred = prophet_test_pred[:min_len]\n#         residual_test_true = residual_test_true[:min_len]\n#         residual_test_pred = residual_test_pred[:min_len]\n        \n#         # Metrics\n#         prophet_metrics = calculate_metrics(y_test_true, prophet_test_pred, \"Prophet\")\n#         hybrid_metrics = calculate_metrics(y_test_true, hybrid_test_pred, \"Hybrid\")\n        \n#         # Metrics cho Residuals (Raw Space)\n#         lstm_metrics = calculate_metrics(residual_test_true, residual_test_pred, \"LSTM_Residuals\")\n        \n#         residual_mape = np.mean(\n#             np.abs((residual_test_true - residual_test_pred) / (np.abs(residual_test_true) + 1e-8))\n#         ) * 100\n        \n#         if verbose:\n#             print(f\"\\n>>> RESULT (Resolution: {resolution}) - NO LOG TRANSFORM <<<\")\n#             print(\"-\" * 60)\n#             print(f\" LSTM Residuals - MAPE: {residual_mape:.2f}% (Prediction of Raw Errors)\")\n#             print(\"-\" * 60)\n#             print(\n#                 f\" Prophet - MAE: {prophet_metrics['MAE']:.2f}, \"\n#                 f\"MSE: {prophet_metrics['MSE']:.2f}, \"\n#                 f\"MAPE: {prophet_metrics['MAPE']:.2f}%, \"\n#                 f\"RMSE: {prophet_metrics['RMSE']:.2f}\"\n#             )\n#             print(\n#                 f\" Hybrid  - MAE: {hybrid_metrics['MAE']:.2f}, \"\n#                 f\"MSE: {hybrid_metrics['MSE']:.2f}, \"\n#                 f\"MAPE: {hybrid_metrics['MAPE']:.2f}%, \"\n#                 f\"RMSE: {hybrid_metrics['RMSE']:.2f}\"\n#             )\n        \n#         # Save results\n#         elapsed_time = time.time() - start_time\n#         return {\n#             'resolution': resolution,\n#             'target': target,\n#             'prophet_mae': prophet_metrics['MAE'],\n#             'prophet_rmse': prophet_metrics['RMSE'],\n#             'prophet_mse': prophet_metrics['MSE'],\n#             'prophet_mape': prophet_metrics['MAPE'],\n#             'lstm_mae': lstm_metrics['MAE'],\n#             'lstm_rmse': lstm_metrics['RMSE'],\n#             'lstm_mse': lstm_metrics['MSE'],\n#             'lstm_mape': lstm_metrics['MAPE'],\n#             'hybrid_mae': hybrid_metrics['MAE'],\n#             'hybrid_rmse': hybrid_metrics['RMSE'],\n#             'hybrid_mse': hybrid_metrics['MSE'],\n#             'hybrid_mape': hybrid_metrics['MAPE'],\n#             'hybrid_r2': hybrid_metrics['R2'],\n#             'residual_mape_test': residual_mape,\n#             'training_time_sec': elapsed_time,\n#             'results_dir': results_dir\n#         }\n\n#     except Exception as e:\n#         print(f\"\\nâŒ ERROR: {str(e)}\")\n#         import traceback\n#         traceback.print_exc()\n#         return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:14:03.503753Z","iopub.execute_input":"2026-02-02T13:14:03.504000Z","iopub.status.idle":"2026-02-02T13:14:03.523077Z","shell.execute_reply.started":"2026-02-02T13:14:03.503981Z","shell.execute_reply":"2026-02-02T13:14:03.522373Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# # ===========================================================================================\n# # CELL 5: MAIN HYBRID TRAINING FUNCTION (UPGRADE: SETUP_1 ARCHITECTURE + STORM MASKING)\n# # ===========================================================================================\n# from sklearn.preprocessing import MinMaxScaler\n# from keras.layers import Bidirectional, LSTM, Dense, Dropout\n# from keras.models import Sequential\n# from keras.losses import Huber\n# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# from prophet import Prophet\n# import numpy as np\n# import pandas as pd\n# import os\n# import time\n# import pickle\n\n# def train_hybrid_model(resolution, target, verbose=True):\n#     \"\"\"\n#     UPGRADED HYBRID MODEL:\n#     - Data: Log Transformed + Storm Masking (Best Data Practice).\n#     - Model: Setup_1 Architecture (Scaler -1to1, Bottleneck LSTM).\n#     - Goal: Optimized for Autoscaling (Robust short-term forecasting).\n#     \"\"\"\n#     if verbose:\n#         print(f\"\\n{'='*70}\")\n#         print(f\"TRAINING: Hybrid Upgrade (Setup_1 Style) | {resolution} | {target}\")\n#         print(f\"{'='*70}\")\n    \n#     start_time = time.time()\n    \n#     # --- Cáº¤U HÃŒNH ---\n#     # Láº¥y params (náº¿u chÆ°a cÃ³ dict thÃ¬ dÃ¹ng default)\n#     try:\n#         params = RESOLUTION_PARAMS[resolution]\n#     except:\n#         params = {'window': 12, 'lstm_units': 50, 'epochs': 50, 'batch_size': 16}\n        \n#     window = params['window']\n#     lstm_units = params['lstm_units'] # Layer 1\n#     lstm_units_2 = 20                 # Layer 2 (Bottleneck tá»« Setup_1)\n#     epochs = params['epochs']\n#     batch_size = params['batch_size']\n    \n#     results_dir = f\"{RESULTS_BASE_DIR}/{resolution}_{target}_upgrade\"\n#     os.makedirs(results_dir, exist_ok=True)\n#     os.makedirs(f\"{results_dir}/prophet_model\", exist_ok=True)\n    \n#     try:\n#         # ==================\n#         # 1. LOAD DATA & STORM MASKING (Váº«n giá»¯ Ä‘á»ƒ trÃ¡nh há»c rÃ¡c tá»« bÃ£o)\n#         # ==================\n#         if verbose: print(f\"[1/7] Loading data & Masking Storm...\")\n        \n#         train_df = pd.read_csv(f\"{DATA_DIR}/train_{resolution}.csv\", index_col=0, parse_dates=True)\n#         test_df = pd.read_csv(f\"{DATA_DIR}/test_{resolution}.csv\", index_col=0, parse_dates=True)\n        \n#         y_test_raw_true = test_df[target].values\n\n#         # Xá»­ lÃ½ bÃ£o (GÃ¡n NaN)\n#         storm_start = pd.Timestamp(\"1995-08-01 14:52:01\")\n#         storm_end   = pd.Timestamp(\"1995-08-03 04:36:13\")\n#         mask = (train_df.index >= storm_start) & (train_df.index <= storm_end)\n#         train_df.loc[mask, target] = None \n        \n#         # Log Transform (Giá»¯ láº¡i vÃ¬ Autoscaling cáº§n xá»­ lÃ½ spikes mÆ°á»£t hÆ¡n)\n#         train_df[target] = np.log1p(train_df[target])\n#         test_df[target] = np.log1p(test_df[target])\n        \n#         full_df = pd.concat([train_df, test_df]).sort_index()\n#         train_size = len(train_df)\n        \n#         # ==================\n#         # 2. TRAIN PROPHET\n#         # ==================\n#         if verbose: print(f\"\\n[2/7] Training Prophet...\")\n        \n#         prophet_train = prepare_prophet_data(train_df, target)\n        \n#         prophet_model = Prophet(\n#             changepoint_prior_scale=5.1, \n#             seasonality_prior_scale=30,\n#             seasonality_mode='multiplicative',\n#         )\n#         prophet_model.add_seasonality(name='daily_high_freq', period=1, fourier_order=50)\n#         prophet_model.add_seasonality(name='weekly_high_freq', period=7, fourier_order=20)\n#         prophet_model.add_regressor('hour')\n#         prophet_model.add_regressor('day_of_week')\n#         prophet_model.add_regressor('is_weekend')\n        \n#         prophet_model.fit(prophet_train)\n        \n#         prophet_full = prepare_prophet_data(full_df, target)\n#         prophet_forecast = prophet_model.predict(prophet_full[['ds', 'hour', 'day_of_week', 'is_weekend']])\n        \n#         # ==================\n#         # 3. COMPUTE RESIDUALS & PREPARE LSTM\n#         # ==================\n#         full_df['yhat_prophet'] = prophet_forecast['yhat'].values\n#         full_df['residual'] = full_df[target] - full_df['yhat_prophet']\n#         full_df['residual'] = full_df['residual'].fillna(0) # Fill 0 cho vÃ¹ng bÃ£o\n        \n#         # --- [UPGRADE Tá»ª SETUP_1]: Scaler (-1, 1) ---\n#         # Tá»‘t hÆ¡n cho residuals vÃ¬ dá»¯ liá»‡u phÃ¢n bá»‘ quanh 0\n#         scaler = MinMaxScaler(feature_range=(-1, 1))\n        \n#         residual_train_values = full_df.iloc[:train_size][['residual']].values\n#         scaler.fit(residual_train_values)\n#         residual_train_scaled = scaler.transform(residual_train_values)\n        \n#         X_train, y_train = make_sequences(residual_train_scaled.flatten(), window)\n#         X_train = X_train.reshape(-1, window, 1)\n        \n#         # Split Valid\n#         val_ratio = 0.2\n#         val_size = int(len(X_train) * val_ratio)\n#         X_train_sub = X_train[:-val_size]\n#         y_train_sub = y_train[:-val_size]\n#         X_val = X_train[-val_size:]\n#         y_val = y_train[-val_size:]\n        \n#         # ==================\n#         # 5. TRAIN LSTM (UPGRADE: BOTTLENECK ARCHITECTURE)\n#         # ==================\n#         if verbose: print(f\"\\n[5/7] Training LSTM (Setup_1 Architecture: 50 -> 20)...\")\n        \n#         # Kiáº¿n trÃºc Ã©p mÃ´ hÃ¬nh há»c Ä‘áº·c trÆ°ng quan trá»ng (Setup_1)\n#         lstm_model = Sequential([\n#             Bidirectional(LSTM(lstm_units, return_sequences=True, input_shape=(window, 1))),\n#             Dropout(0.2),\n#             Bidirectional(LSTM(lstm_units_2, return_sequences=False)), # Giáº£m xuá»‘ng 20 units\n#             Dense(1)\n#         ])\n        \n#         # Huber Loss váº«n lÃ  chÃ¢n Ã¡i cho Autoscaling (chá»‘ng nhiá»…u tá»‘t hÆ¡n MSE)\n#         lstm_model.compile(optimizer='adam', loss=Huber(delta=1.0), metrics=['mae'])\n        \n#         callbacks = [\n#             EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss', verbose=1),\n#             ReduceLROnPlateau(patience=5, factor=0.5, monitor='val_loss', verbose=1)\n#         ]\n        \n#         history = lstm_model.fit(\n#             X_train_sub, y_train_sub,\n#             validation_data=(X_val, y_val),\n#             epochs=epochs,\n#             batch_size=batch_size,\n#             callbacks=callbacks,\n#             verbose=1\n#         )\n        \n#         # ==================\n#         # 6. HYBRID PREDICTION\n#         # ==================\n#         if verbose: print(f\"\\n[6/7] Generating predictions...\")\n        \n#         # Predict Residuals (All data)\n#         residual_all_values = full_df[['residual']].values\n#         residual_all_scaled = scaler.transform(residual_all_values)\n        \n#         X_all, _ = make_sequences(residual_all_scaled.flatten(), window)\n#         X_all = X_all.reshape(-1, window, 1)\n        \n#         residual_pred_scaled = lstm_model.predict(X_all, verbose=0)\n#         residual_pred_log = scaler.inverse_transform(residual_pred_scaled).flatten()\n        \n#         # Reconstruct Hybrid (Log -> Exp)\n#         prophet_pred_log = full_df['yhat_prophet'].iloc[window:].values\n#         hybrid_pred_log = prophet_pred_log + residual_pred_log\n        \n#         hybrid_pred_final = np.expm1(hybrid_pred_log)\n#         prophet_pred_final = np.expm1(prophet_pred_log)\n        \n#         # ==================\n#         # 7. EVALUATION\n#         # ==================\n#         if verbose: print(f\"\\n[7/7] Evaluating...\")\n\n#         lstm_test_start_idx = train_size - window\n        \n#         hybrid_test_pred = hybrid_pred_final[lstm_test_start_idx:]\n#         prophet_test_pred = prophet_pred_final[lstm_test_start_idx:]\n#         residual_test_pred = residual_pred_log[lstm_test_start_idx:] \n\n#         residual_test_true = full_df['residual'].iloc[train_size:].values\n        \n#         min_len = min(len(y_test_raw_true), len(hybrid_test_pred), len(residual_test_true))\n        \n#         y_test_true = y_test_raw_true[:min_len]\n#         hybrid_test_pred = hybrid_test_pred[:min_len]\n#         prophet_test_pred = prophet_test_pred[:min_len]\n#         residual_test_true = residual_test_true[:min_len]\n#         residual_test_pred = residual_test_pred[:min_len]\n        \n#         # Metrics\n#         prophet_metrics = calculate_metrics(y_test_true, prophet_test_pred, \"Prophet\")\n#         hybrid_metrics = calculate_metrics(y_test_true, hybrid_test_pred, \"Hybrid\")\n        \n#         # Residual MAPE\n#         residual_mape = np.mean(\n#             np.abs((residual_test_true - residual_test_pred) / (np.abs(residual_test_true) + 1e-8))\n#         ) * 100\n        \n#         if verbose:\n#             print(f\"\\n>>> RESULT (Resolution: {resolution}) - UPGRADED <<<\")\n#             print(\"-\" * 60)\n#             print(f\" LSTM Residuals - MAPE: {residual_mape:.2f}%\")\n#             print(\"-\" * 60)\n#             print(f\" Prophet - MAE: {prophet_metrics['MAE']:.2f} | MAPE: {prophet_metrics['MAPE']:.2f}%\")\n#             print(f\" Hybrid  - MAE: {hybrid_metrics['MAE']:.2f} | MAPE: {hybrid_metrics['MAPE']:.2f}%\")\n        \n#         # Save results\n#         elapsed_time = time.time() - start_time\n#         return {\n#             'resolution': resolution,\n#             'target': target,\n#             'hybrid_mae': hybrid_metrics['MAE'],\n#             'hybrid_mape': hybrid_metrics['MAPE'],\n#             'residual_mape': residual_mape,\n#             'training_time_sec': elapsed_time\n#         }\n\n#     except Exception as e:\n#         print(f\"\\nâŒ ERROR: {str(e)}\")\n#         import traceback\n#         traceback.print_exc()\n#         return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:14:03.524381Z","iopub.execute_input":"2026-02-02T13:14:03.524827Z","iopub.status.idle":"2026-02-02T13:14:03.540076Z","shell.execute_reply.started":"2026-02-02T13:14:03.524805Z","shell.execute_reply":"2026-02-02T13:14:03.539595Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# # ===========================================================================================\n# # CELL 5: SETUP_1 REVIVAL (RAW DATA + STORM MASKING + ONE-STEP AHEAD)\n# # ===========================================================================================\n# from sklearn.preprocessing import MinMaxScaler\n# from keras.layers import Bidirectional, LSTM, Dense, Dropout\n# from keras.models import Sequential\n# from keras.losses import Huber\n# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# from prophet import Prophet\n# import numpy as np\n# import pandas as pd\n# import os\n# import time\n# import pickle\n\n# def train_hybrid_model(resolution, target, verbose=True):\n#     if verbose:\n#         print(f\"\\n{'='*70}\")\n#         print(f\"TRAINING: Setup_1 Revival (RAW DATA + One-Step Ahead) | {resolution} | {target}\")\n#         print(f\"{'='*70}\")\n    \n#     start_time = time.time()\n    \n#     # --- Cáº¤U HÃŒNH ---\n#     try: params = RESOLUTION_PARAMS[resolution]\n#     except: params = {'window': 12, 'lstm_units': 50, 'epochs': 50, 'batch_size': 16}\n        \n#     window = params['window']\n#     lstm_units = params['lstm_units'] \n#     lstm_units_2 = 20  # Bottleneck tá»« Setup_1\n#     epochs = params['epochs']\n#     batch_size = params['batch_size']\n    \n#     results_dir = f\"{RESULTS_BASE_DIR}/{resolution}_{target}_setup1_revival\"\n#     os.makedirs(results_dir, exist_ok=True)\n#     os.makedirs(f\"{results_dir}/prophet_model\", exist_ok=True)\n    \n#     try:\n#         # ==================\n#         # 1. LOAD DATA & STORM MASKING\n#         # ==================\n#         if verbose: print(f\"[1/7] Loading Data (RAW)...\")\n#         train_df = pd.read_csv(f\"{DATA_DIR}/train_{resolution}.csv\", index_col=0, parse_dates=True)\n#         test_df = pd.read_csv(f\"{DATA_DIR}/test_{resolution}.csv\", index_col=0, parse_dates=True)\n        \n#         y_test_raw_true = test_df[target].values\n\n#         # Masking Storm\n#         storm_start = pd.Timestamp(\"1995-08-01 14:52:01\")\n#         storm_end   = pd.Timestamp(\"1995-08-03 04:36:13\")\n#         mask = (train_df.index >= storm_start) & (train_df.index <= storm_end)\n#         train_df.loc[mask, target] = None \n        \n#         # --- QUAN TRá»ŒNG: KHÃ”NG DÃ™NG LOG TRANSFORM ---\n#         # Cháº¡y trá»±c tiáº¿p trÃªn Raw Data\n        \n#         full_df = pd.concat([train_df, test_df]).sort_index()\n#         train_size = len(train_df)\n        \n#         # ==================\n#         # 2. TRAIN PROPHET\n#         # ==================\n#         if verbose: print(f\"\\n[2/7] Training Prophet (Raw Space)...\")\n#         prophet_train = prepare_prophet_data(train_df, target)\n        \n#         prophet_model = Prophet(\n#             changepoint_prior_scale=5.1, \n#             seasonality_prior_scale=30,\n#             seasonality_mode='multiplicative', # Raw data biáº¿n Ä‘á»™ng máº¡nh nÃªn thá»­ multiplicative\n#         )\n#         prophet_model.add_seasonality(name='daily_high_freq', period=1, fourier_order=50)\n#         prophet_model.add_seasonality(name='weekly_high_freq', period=7, fourier_order=20)\n#         prophet_model.add_regressor('hour')\n#         prophet_model.add_regressor('day_of_week')\n#         prophet_model.add_regressor('is_weekend')\n        \n#         prophet_model.fit(prophet_train)\n        \n#         prophet_full = prepare_prophet_data(full_df, target)\n#         prophet_forecast = prophet_model.predict(prophet_full[['ds', 'hour', 'day_of_week', 'is_weekend']])\n        \n#         # ==================\n#         # 3. COMPUTE RESIDUALS\n#         # ==================\n#         full_df['yhat_prophet'] = prophet_forecast['yhat'].values\n#         # Residual = Thá»±c táº¿ - Prophet\n#         full_df['residual'] = full_df[target] - full_df['yhat_prophet']\n#         full_df['residual'] = full_df['residual'].fillna(0) \n        \n#         # --- SCALER (-1, 1) Cá»¦A SETUP_1 ---\n#         scaler = MinMaxScaler(feature_range=(-1, 1))\n        \n#         residual_train_values = full_df.iloc[:train_size][['residual']].values\n#         scaler.fit(residual_train_values)\n#         residual_train_scaled = scaler.transform(residual_train_values)\n        \n#         X_train, y_train = make_sequences(residual_train_scaled.flatten(), window)\n#         X_train = X_train.reshape(-1, window, 1)\n        \n#         # Split Valid\n#         val_size = int(len(X_train) * 0.2)\n#         X_train_sub, y_train_sub = X_train[:-val_size], y_train[:-val_size]\n#         X_val, y_val = X_train[-val_size:], y_train[-val_size:]\n        \n#         # ==================\n#         # 5. TRAIN LSTM (SETUP_1 ARCHITECTURE)\n#         # ==================\n#         if verbose: print(f\"\\n[5/7] Training LSTM (Bottleneck 50->20)...\")\n        \n#         lstm_model = Sequential([\n#             LSTM(lstm_units, return_sequences=True, input_shape=(window, 1)),\n#             Dropout(0.2),\n#             LSTM(lstm_units, return_sequences=False), # Bottleneck\n#             Dense(1)\n#         ])\n        \n#         lstm_model.compile(optimizer='adam', loss='huber', metrics=['mae'])\n        \n#         lstm_model.fit(X_train_sub, y_train_sub, validation_data=(X_val, y_val), \n#                        epochs=epochs, batch_size=batch_size, verbose=1,\n#                        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n        \n#         # ==================\n#         # 6. HYBRID PREDICTION (ONE-STEP LOGIC)\n#         # ==================\n#         if verbose: print(f\"\\n[6/7] Generating Forecast (Raw Space)...\")\n        \n#         # Táº¡o chuá»—i input cho Test: ÄuÃ´i Train + Residual Test Thá»±c Táº¿\n#         residual_test_true = full_df['residual'].iloc[train_size:].values\n#         residual_train_tail = full_df['residual'].iloc[train_size-window:train_size].values\n        \n#         # Ná»‘i láº¡i\n#         history_stream = np.concatenate([residual_train_tail, residual_test_true])\n#         history_stream_scaled = scaler.transform(history_stream.reshape(-1, 1)).flatten()\n        \n#         # Táº¡o X_test dáº¡ng cuá»™n (Vectorized rolling window - Nhanh hÆ¡n vÃ²ng láº·p for)\n#         # HÃ m make_sequences sáº½ tá»± Ä‘á»™ng táº¡o cÃ¡c cá»­a sá»• trÆ°á»£t [t-window : t]\n#         X_test_rolling, _ = make_sequences(history_stream_scaled, window)\n#         X_test_rolling = X_test_rolling.reshape(-1, window, 1)\n        \n#         # Predict Residuals (Raw Scaled)\n#         residual_test_pred_scaled = lstm_model.predict(X_test_rolling, verbose=0)\n        \n#         # Inverse Scale -> Raw Residuals\n#         residual_test_pred_raw = scaler.inverse_transform(residual_test_pred_scaled).flatten()\n        \n#         # Cá»™ng láº¡i: Hybrid = Prophet (Raw) + LSTM Residual (Raw)\n#         prophet_test_pred_raw = full_df['yhat_prophet'].iloc[train_size:].values\n        \n#         # Cáº¯t khá»›p Ä‘á»™ dÃ i\n#         min_len = min(len(prophet_test_pred_raw), len(residual_test_pred_raw))\n#         hybrid_test_pred_final = prophet_test_pred_raw[:min_len] + residual_test_pred_raw[:min_len]\n        \n#         # Káº¹p giÃ¡ trá»‹ Ã¢m vá» 0 (náº¿u cÃ³)\n#         hybrid_test_pred_final = np.maximum(hybrid_test_pred_final, 0)\n\n#         # ==================\n#         # 7. EVALUATION\n#         # ==================\n#         if verbose: print(f\"\\n[7/7] Evaluating...\")\n\n#         # Cáº¯t dá»¯ liá»‡u thá»±c táº¿ vÃ  dá»± bÃ¡o cho khá»›p nhau\n#         y_test_true = y_test_raw_true[:min_len]\n#         prophet_test_pred = prophet_test_pred_raw[:min_len]\n#         hybrid_test_pred = hybrid_test_pred_final[:min_len]\n        \n#         # TÃ­nh metrics\n#         prophet_metrics = calculate_metrics(y_test_true, prophet_test_pred, \"Prophet\")\n#         hybrid_metrics = calculate_metrics(y_test_true, hybrid_test_pred, \"Hybrid\")\n        \n#         if verbose:\n#             print(f\"\\n>>> RESULT (Resolution: {resolution}) - NO LOG TRANSFORM <<<\")\n#             print(\"-\" * 60)\n#             print(\n#                 f\" Prophet - MAE: {prophet_metrics['MAE']:.2f}, \"\n#                 f\"MSE: {prophet_metrics['MSE']:.2f}, \"\n#                 f\"MAPE: {prophet_metrics['MAPE']:.2f}%, \"\n#                 f\"RMSE: {prophet_metrics['RMSE']:.2f}\"\n#             )\n#             print(\n#                 f\" Hybrid  - MAE: {hybrid_metrics['MAE']:.2f}, \"\n#                 f\"MSE: {hybrid_metrics['MSE']:.2f}, \"\n#                 f\"MAPE: {hybrid_metrics['MAPE']:.2f}%, \"\n#                 f\"RMSE: {hybrid_metrics['RMSE']:.2f}\"\n#             )\n        \n#         # Save results\n#         # LÆ°u CSV Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“\n#         test_timestamps = test_df.index[:min_len]\n#         predictions_df = pd.DataFrame({\n#             'timestamp': test_timestamps,\n#             'actual': y_test_true,\n#             'prophet_pred': prophet_test_pred,\n#             'hybrid_pred': hybrid_test_pred\n#         })\n#         predictions_df.to_csv(f\"{results_dir}/hybrid_predictions.csv\", index=False)\n\n#         elapsed_time = time.time() - start_time\n#         return {\n#             'resolution': resolution,\n#             'target': target,\n#             'prophet_mae': prophet_metrics['MAE'],\n#             'prophet_rmse': prophet_metrics['RMSE'],\n#             'prophet_mse': prophet_metrics['MSE'],\n#             'prophet_mape': prophet_metrics['MAPE'],\n#             'hybrid_mae': hybrid_metrics['MAE'],\n#             'hybrid_rmse': hybrid_metrics['RMSE'],\n#             'hybrid_mse': hybrid_metrics['MSE'],\n#             'hybrid_mape': hybrid_metrics['MAPE'],\n#             'hybrid_r2': hybrid_metrics['R2'],\n#             'results_dir': results_dir\n#         }\n\n#     except Exception as e:\n#         print(f\"\\nâŒ ERROR: {str(e)}\")\n#         import traceback\n#         traceback.print_exc()\n#         return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:14:03.541137Z","iopub.execute_input":"2026-02-02T13:14:03.541426Z","iopub.status.idle":"2026-02-02T13:14:03.565628Z","shell.execute_reply.started":"2026-02-02T13:14:03.541406Z","shell.execute_reply":"2026-02-02T13:14:03.564927Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# ===========================================================================================\n# CELL 5: SETUP_1 REPLICA (RAW DATA + STORM MASKING + EXACT LSTM ARCHITECTURE)\n# ===========================================================================================\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.layers import Bidirectional, LSTM, Dense, Dropout\nfrom keras.models import Sequential\nfrom keras.losses import Huber\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom prophet import Prophet\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\nimport pickle\n\ndef train_hybrid_model(resolution, target, verbose=True):\n    if verbose:\n        print(f\"\\n{'='*70}\")\n        print(f\"TRAINING: Setup_1 Replica (Exact Match) | {resolution} | {target}\")\n        print(f\"{'='*70}\")\n    \n    start_time = time.time()\n    \n    # --- Cáº¤U HÃŒNH ---\n    try: params = RESOLUTION_PARAMS[resolution]\n    except: params = {'window': 12, 'lstm_units': 50, 'epochs': 50, 'batch_size': 16}\n        \n    window = params['window'] # ChÃ­nh lÃ  look_back trong code cá»§a báº¡n\n    epochs = params['epochs']\n    batch_size = params['batch_size']\n    \n    results_dir = f\"{RESULTS_BASE_DIR}/{resolution}_{target}_setup1_replica\"\n    os.makedirs(results_dir, exist_ok=True)\n    os.makedirs(f\"{results_dir}/prophet_model\", exist_ok=True)\n    \n    try:\n        # ==================\n        # 1. LOAD DATA & STORM MASKING\n        # ==================\n        if verbose: print(f\"[1/7] Loading Data (RAW)...\")\n        train_df = pd.read_csv(f\"{DATA_DIR}/train_{resolution}.csv\", index_col=0, parse_dates=True)\n        test_df = pd.read_csv(f\"{DATA_DIR}/test_{resolution}.csv\", index_col=0, parse_dates=True)\n        \n        y_test_raw_true = test_df[target].values\n\n        # Masking Storm\n        storm_start = pd.Timestamp(\"1995-08-01 14:52:01\")\n        storm_end   = pd.Timestamp(\"1995-08-03 04:36:13\")\n        mask = (train_df.index >= storm_start) & (train_df.index <= storm_end)\n        train_df.loc[mask, target] = None \n        \n        # KHÃ”NG DÃ™NG LOG (Raw Data)\n        \n        full_df = pd.concat([train_df, test_df]).sort_index()\n        train_size = len(train_df)\n        \n        # ==================\n        # 2. TRAIN PROPHET\n        # ==================\n        if verbose: print(f\"\\n[2/7] Training Prophet (Raw Space)...\")\n        prophet_train = prepare_prophet_data(train_df, target)\n        \n        prophet_model = Prophet(\n            changepoint_prior_scale=5.1, \n            seasonality_prior_scale=30,\n            seasonality_mode='multiplicative',\n        )\n        prophet_model.add_seasonality(name='daily_high_freq', period=1, fourier_order=50)\n        prophet_model.add_seasonality(name='weekly_high_freq', period=7, fourier_order=20)\n        prophet_model.add_regressor('hour')\n        prophet_model.add_regressor('day_of_week')\n        prophet_model.add_regressor('is_weekend')\n        \n        prophet_model.fit(prophet_train)\n        \n        prophet_full = prepare_prophet_data(full_df, target)\n        prophet_forecast = prophet_model.predict(prophet_full[['ds', 'hour', 'day_of_week', 'is_weekend']])\n        \n        # ==================\n        # 3. COMPUTE RESIDUALS\n        # ==================\n        full_df['yhat_prophet'] = prophet_forecast['yhat'].values\n        full_df['residual'] = full_df[target] - full_df['yhat_prophet']\n        full_df['residual'] = full_df['residual'].fillna(0) \n        \n        # --- SCALER (-1, 1) Cá»¦A SETUP_1 ---\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        \n        residual_train_values = full_df.iloc[:train_size][['residual']].values\n        scaler.fit(residual_train_values)\n        residual_train_scaled = scaler.transform(residual_train_values)\n        \n        X_train, y_train = make_sequences(residual_train_scaled.flatten(), window)\n        X_train = X_train.reshape(-1, window, 1)\n        \n        # Split Valid\n        val_size = int(len(X_train) * 0.2)\n        X_train_sub, y_train_sub = X_train[:-val_size], y_train[:-val_size]\n        X_val, y_val = X_train[-val_size:], y_train[-val_size:]\n        \n        # ==================\n        # 5. TRAIN LSTM (EXACT SETUP_1 SYNTAX)\n        # ==================\n        if verbose: print(f\"\\n[5/7] Training LSTM (Exact Setup_1 Code)...\")\n        \n        # --- [CHá»ˆNH Sá»¬A] GIá»NG Há»†T SETUP_1 ---\n        lstm_model = Sequential()\n        # Layer 1: 50 units\n        lstm_model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(window, 1)))\n        lstm_model.add(Dropout(0.2))\n        # Layer 2: 20 units (Bottleneck)\n        lstm_model.add(Bidirectional(LSTM(20))) # Máº·c Ä‘á»‹nh return_sequences=False\n        lstm_model.add(Dense(1))\n        \n        # Compile: dÃ¹ng string 'huber' vÃ  'adam' cho giá»‘ng Setup_1\n        lstm_model.compile(loss='huber', optimizer='adam') \n        \n        # Fit\n        lstm_model.fit(X_train_sub, y_train_sub, validation_data=(X_val, y_val), \n                       epochs=epochs, batch_size=batch_size, verbose=1,\n                       callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n        \n        # ==================\n        # 6. HYBRID PREDICTION (VARIABLE NAMES MATCH SETUP_1)\n        # ==================\n        if verbose: print(f\"\\n[6/7] Generating Forecast (Concatenate Style)...\")\n        \n        # 1. Láº¥y dá»¯ liá»‡u\n        residual_test_true = full_df['residual'].iloc[train_size:].values\n        # Láº¥y Ä‘uÃ´i train (chÃ­nh lÃ  train_residuals[-look_back:] trong Setup_1)\n        residual_train_tail = full_df['residual'].iloc[train_size-window:train_size].values\n        \n        # 2. Ná»‘i láº¡i (GIá»NG BIáº¾N total_residuals)\n        # total_residuals = np.concatenate((train_residuals[-look_back:], test_residuals_true))\n        total_residuals = np.concatenate([residual_train_tail, residual_test_true])\n        \n        # 3. Scale (-1, 1)\n        # total_residuals_scaled = resid_scaler.transform(...)\n        total_residuals_scaled = scaler.transform(total_residuals.reshape(-1, 1)).flatten()\n        \n        # 4. Táº¡o X_test (Sliding Window)\n        X_test_rolling, _ = make_sequences(total_residuals_scaled, window)\n        X_test_rolling = X_test_rolling.reshape(-1, window, 1)\n        \n        # 5. Predict\n        residual_test_pred_scaled = lstm_model.predict(X_test_rolling, verbose=0)\n        \n        # 6. Inverse Scale\n        residual_test_pred_raw = scaler.inverse_transform(residual_test_pred_scaled).flatten()\n        \n        # 7. Cá»™ng láº¡i: Prophet + LSTM\n        prophet_test_pred_raw = full_df['yhat_prophet'].iloc[train_size:].values\n        \n        # Cáº¯t khá»›p\n        min_len = min(len(prophet_test_pred_raw), len(residual_test_pred_raw))\n        hybrid_test_pred_final = prophet_test_pred_raw[:min_len] + residual_test_pred_raw[:min_len]\n        \n        # Káº¹p giÃ¡ trá»‹ Ã¢m vá» 0 (Setup_1 cÃ³ bÆ°á»›c nÃ y: np.maximum(final_pred, 0))\n        hybrid_test_pred_final = np.maximum(hybrid_test_pred_final, 0)\n\n        # ==================\n        # 7. EVALUATION\n        # ==================\n        if verbose: print(f\"\\n[7/7] Evaluating...\")\n\n        y_test_true = y_test_raw_true[:min_len]\n        prophet_test_pred = prophet_test_pred_raw[:min_len]\n        hybrid_test_pred = hybrid_test_pred_final[:min_len]\n        \n        # Metrics\n        prophet_metrics = calculate_metrics(y_test_true, prophet_test_pred, \"Prophet\")\n        hybrid_metrics = calculate_metrics(y_test_true, hybrid_test_pred, \"Hybrid\")\n        \n        if verbose:\n            print(f\"\\n>>> RESULT (Resolution: {resolution}) - SETUP_1 REPLICA <<<\")\n            print(\"-\" * 60)\n            print(\n                f\" Prophet - MAE: {prophet_metrics['MAE']:.2f}, \"\n                f\"MSE: {prophet_metrics['MSE']:.2f}, \"\n                f\"MAPE: {prophet_metrics['MAPE']:.2f}%, \"\n                f\"RMSE: {prophet_metrics['RMSE']:.2f}\"\n            )\n            print(\n                f\" Hybrid  - MAE: {hybrid_metrics['MAE']:.2f}, \"\n                f\"MSE: {hybrid_metrics['MSE']:.2f}, \"\n                f\"MAPE: {hybrid_metrics['MAPE']:.2f}%, \"\n                f\"RMSE: {hybrid_metrics['RMSE']:.2f}\"\n            )\n        \n        # Save results\n        test_timestamps = test_df.index[:min_len]\n        predictions_df = pd.DataFrame({\n            'timestamp': test_timestamps,\n            'actual': y_test_true,\n            'prophet_pred': prophet_test_pred,\n            'hybrid_pred': hybrid_test_pred\n        })\n        predictions_df.to_csv(f\"{results_dir}/hybrid_predictions.csv\", index=False)\n\n        elapsed_time = time.time() - start_time\n        return {\n            'resolution': resolution,\n            'target': target,\n            'prophet_mae': prophet_metrics['MAE'],\n            'prophet_rmse': prophet_metrics['RMSE'],\n            'prophet_mse': prophet_metrics['MSE'],\n            'prophet_mape': prophet_metrics['MAPE'],\n             'prophet_r2': prophet_metrics['R2'],\n            'hybrid_mae': hybrid_metrics['MAE'],\n            'hybrid_rmse': hybrid_metrics['RMSE'],\n            'hybrid_mse': hybrid_metrics['MSE'],\n            'hybrid_mape': hybrid_metrics['MAPE'],\n            'hybrid_r2': hybrid_metrics['R2'],\n            'results_dir': results_dir\n        }\n\n    except Exception as e:\n        print(f\"\\nâŒ ERROR: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:22:50.222846Z","iopub.execute_input":"2026-02-02T13:22:50.223137Z","iopub.status.idle":"2026-02-02T13:22:50.244936Z","shell.execute_reply.started":"2026-02-02T13:22:50.223113Z","shell.execute_reply":"2026-02-02T13:22:50.243974Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# ===========================\n# CELL 6: RUN ALL CONFIGURATIONS\n# ===========================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"STARTING AUTOMATED HYBRID TRAINING PIPELINE\")\nprint(\"=\"*70)\n\nall_results = []\ntotal_configs = len(RESOLUTIONS) * len(TARGETS)\ncurrent_config = 0\n\npipeline_start_time = time.time()\n\nfor resolution in RESOLUTIONS:\n    for target in TARGETS:\n        current_config += 1\n        \n        print(f\"\\n\\n{'#'*70}\")\n        print(f\"CONFIGURATION {current_config}/{total_configs}\")\n        print(f\"{'#'*70}\")\n        \n        result = train_hybrid_model(resolution, target, verbose=True)\n        \n        if result is not None:\n            all_results.append(result)\n            print(f\"\\nâœ… Configuration {current_config}/{total_configs} completed successfully\")\n        else:\n            print(f\"\\nâŒ Configuration {current_config}/{total_configs} failed\")\n        \n        # Progress update\n        elapsed = time.time() - pipeline_start_time\n        avg_time = elapsed / current_config\n        remaining = (total_configs - current_config) * avg_time\n        \n        print(f\"\\nðŸ“Š Progress: {current_config}/{total_configs} ({current_config/total_configs*100:.1f}%)\")\n        print(f\"   Elapsed: {elapsed/60:.1f} min | Est. remaining: {remaining/60:.1f} min\")\n\ntotal_elapsed = time.time() - pipeline_start_time\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ALL CONFIGURATIONS COMPLETED\")\nprint(\"=\"*70)\nprint(f\"  Total time: {total_elapsed/60:.1f} minutes\")\nprint(f\"  Successful: {len(all_results)}/{total_configs}\")\nprint(f\"  Failed: {total_configs - len(all_results)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:22:51.402869Z","iopub.execute_input":"2026-02-02T13:22:51.403156Z","iopub.status.idle":"2026-02-02T13:27:28.158288Z","shell.execute_reply.started":"2026-02-02T13:22:51.403132Z","shell.execute_reply":"2026-02-02T13:27:28.157716Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nSTARTING AUTOMATED HYBRID TRAINING PIPELINE\n======================================================================\n\n\n######################################################################\nCONFIGURATION 1/4\n######################################################################\n\n======================================================================\nTRAINING: Setup_1 Replica (Exact Match) | 5min | request_count\n======================================================================\n[1/7] Loading Data (RAW)...\n\n[2/7] Training Prophet (Raw Space)...\n","output_type":"stream"},{"name":"stderr","text":"13:22:53 - cmdstanpy - INFO - Chain [1] start processing\n13:23:27 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"\n[5/7] Training LSTM (Exact Setup_1 Code)...\nEpoch 1/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0020\nEpoch 2/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0027 - val_loss: 0.0020\nEpoch 3/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0020\nEpoch 4/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0020\nEpoch 5/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 6/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 7/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 8/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 9/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 10/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 11/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 12/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 13/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 14/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 15/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 16/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 17/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 18/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 19/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0019\nEpoch 20/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0019\n\n[6/7] Generating Forecast (Concatenate Style)...\n\n[7/7] Evaluating...\n\n>>> RESULT (Resolution: 5min) - SETUP_1 REPLICA <<<\n------------------------------------------------------------\n Prophet - MAE: 57.08, MSE: 6615.84, MAPE: 36.60%, RMSE: 81.34\n Hybrid  - MAE: 34.96, MSE: 2208.31, MAPE: 27.71%, RMSE: 46.99\n\nâœ… Configuration 1/4 completed successfully\n\nðŸ“Š Progress: 1/4 (25.0%)\n   Elapsed: 1.5 min | Est. remaining: 4.5 min\n\n\n######################################################################\nCONFIGURATION 2/4\n######################################################################\n\n======================================================================\nTRAINING: Setup_1 Replica (Exact Match) | 5min | total_bytes\n======================================================================\n[1/7] Loading Data (RAW)...\n\n[2/7] Training Prophet (Raw Space)...\n","output_type":"stream"},{"name":"stderr","text":"13:24:23 - cmdstanpy - INFO - Chain [1] start processing\n13:24:47 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"\n[5/7] Training LSTM (Exact Setup_1 Code)...\nEpoch 1/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0039\nEpoch 2/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0038\nEpoch 3/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0037\nEpoch 4/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0037\nEpoch 5/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0037\nEpoch 6/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0037\nEpoch 7/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0037\nEpoch 8/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 9/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 10/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 11/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 12/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 13/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0037\nEpoch 14/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 15/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 16/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 17/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 18/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 19/50\n\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0037\n\n[6/7] Generating Forecast (Concatenate Style)...\n\n[7/7] Evaluating...\n\n>>> RESULT (Resolution: 5min) - SETUP_1 REPLICA <<<\n------------------------------------------------------------\n Prophet - MAE: 928196.66, MSE: 1663852821668.35, MAPE: 38.37%, RMSE: 1289904.19\n Hybrid  - MAE: 632106.99, MSE: 717804046790.15, MAPE: 29.33%, RMSE: 847233.17\n\nâœ… Configuration 2/4 completed successfully\n\nðŸ“Š Progress: 2/4 (50.0%)\n   Elapsed: 2.8 min | Est. remaining: 2.8 min\n\n\n######################################################################\nCONFIGURATION 3/4\n######################################################################\n\n======================================================================\nTRAINING: Setup_1 Replica (Exact Match) | 15min | request_count\n======================================================================\n[1/7] Loading Data (RAW)...\n\n[2/7] Training Prophet (Raw Space)...\n","output_type":"stream"},{"name":"stderr","text":"13:25:38 - cmdstanpy - INFO - Chain [1] start processing\n13:25:46 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"\n[5/7] Training LSTM (Exact Setup_1 Code)...\nEpoch 1/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0249 - val_loss: 0.0017\nEpoch 2/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0017\nEpoch 3/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0017\nEpoch 4/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0017\nEpoch 5/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0017\nEpoch 6/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0017\nEpoch 7/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0017\nEpoch 8/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0017\nEpoch 9/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0017\nEpoch 10/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0017\nEpoch 11/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0017\nEpoch 12/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0017\nEpoch 13/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0016\nEpoch 14/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0017\nEpoch 15/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0017\nEpoch 16/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0016\nEpoch 17/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0016\nEpoch 18/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0016\nEpoch 19/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0016\nEpoch 20/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0016\nEpoch 21/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 22/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 23/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 24/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 25/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 26/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 27/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 28/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 29/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 30/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 31/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 32/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 33/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 34/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 35/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 36/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 37/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 38/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 39/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0016\nEpoch 40/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 41/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 42/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 43/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 44/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 45/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 46/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 47/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 48/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 49/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\nEpoch 50/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0016\n\n[6/7] Generating Forecast (Concatenate Style)...\n\n[7/7] Evaluating...\n\n>>> RESULT (Resolution: 15min) - SETUP_1 REPLICA <<<\n------------------------------------------------------------\n Prophet - MAE: 154.81, MSE: 51201.37, MAPE: 24.46%, RMSE: 226.28\n Hybrid  - MAE: 83.81, MSE: 13171.50, MAPE: 16.03%, RMSE: 114.77\n\nâœ… Configuration 3/4 completed successfully\n\nðŸ“Š Progress: 3/4 (75.0%)\n   Elapsed: 3.7 min | Est. remaining: 1.2 min\n\n\n######################################################################\nCONFIGURATION 4/4\n######################################################################\n\n======================================================================\nTRAINING: Setup_1 Replica (Exact Match) | 15min | total_bytes\n======================================================================\n[1/7] Loading Data (RAW)...\n\n[2/7] Training Prophet (Raw Space)...\n","output_type":"stream"},{"name":"stderr","text":"13:26:32 - cmdstanpy - INFO - Chain [1] start processing\n13:26:38 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"\n[5/7] Training LSTM (Exact Setup_1 Code)...\nEpoch 1/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0108 - val_loss: 0.0045\nEpoch 2/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0045\nEpoch 3/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0044\nEpoch 4/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0044\nEpoch 5/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0043\nEpoch 6/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0043\nEpoch 7/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0043\nEpoch 8/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0043\nEpoch 9/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0044\nEpoch 10/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0043\nEpoch 11/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0043\nEpoch 12/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0043\nEpoch 13/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0043\nEpoch 14/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0044\nEpoch 15/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0044\nEpoch 16/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0043\nEpoch 17/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0044\nEpoch 18/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 19/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 20/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 21/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 22/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 23/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 24/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 25/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 26/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 27/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 28/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 29/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0043\nEpoch 30/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 31/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 32/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 33/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 34/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0042\nEpoch 35/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 36/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0042\nEpoch 37/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0042\nEpoch 38/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0042\nEpoch 39/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0042\nEpoch 40/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0042\nEpoch 41/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0042\nEpoch 42/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0042\nEpoch 43/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0042\nEpoch 44/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0042\nEpoch 45/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0047 - val_loss: 0.0042\nEpoch 46/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0042\nEpoch 47/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0042\nEpoch 48/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0042\nEpoch 49/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0042\nEpoch 50/50\n\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0042\n\n[6/7] Generating Forecast (Concatenate Style)...\n\n[7/7] Evaluating...\n\n>>> RESULT (Resolution: 15min) - SETUP_1 REPLICA <<<\n------------------------------------------------------------\n Prophet - MAE: 2491716.33, MSE: 12148277865859.69, MAPE: 30.77%, RMSE: 3485437.97\n Hybrid  - MAE: 1502758.73, MSE: 3992072664394.16, MAPE: 22.56%, RMSE: 1998017.18\n\nâœ… Configuration 4/4 completed successfully\n\nðŸ“Š Progress: 4/4 (100.0%)\n   Elapsed: 4.6 min | Est. remaining: 0.0 min\n\n======================================================================\nALL CONFIGURATIONS COMPLETED\n======================================================================\n  Total time: 4.6 minutes\n  Successful: 4/4\n  Failed: 0\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"# ===========================\n# CELL 7: CREATE COMPREHENSIVE BENCHMARK\n# ===========================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"GENERATING COMPREHENSIVE BENCHMARK\")\nprint(\"=\"*70)\n\n# Create benchmark directory\nbenchmark_dir = f\"{RESULTS_BASE_DIR}/FINAL_BENCHMARK\"\nos.makedirs(benchmark_dir, exist_ok=True)\n\n# Convert results to DataFrame\nbenchmark_df = pd.DataFrame(all_results)\n\n# Save comprehensive comparison\nbenchmark_file = f\"{benchmark_dir}/comprehensive_comparison.csv\"\nbenchmark_df.to_csv(benchmark_file, index=False)\nprint(f\"\\nâœ“ Benchmark saved: {benchmark_file}\")\n\nprint(\"\\nðŸ“Š BENCHMARK RESULTS:\\n\")\ndisplay(benchmark_df.style.background_gradient(\n    cmap='RdYlGn_r', \n    subset=['prophet_mae', 'hybrid_mae', 'hybrid_rmse']\n).format({\n    'prophet_mae': '{:.2f}',\n    'prophet_rmse': '{:.2f}',\n    'prophet_mse': '{:.2f}',\n    'prophet_mape': '{:.2f}%',\n    'prophet_r2': '{:.4f}',\n    'hybrid_mae': '{:.2f}',\n    'hybrid_rmse': '{:.2f}',\n    'hybrid_mse': '{:.2f}',\n    'hybrid_mape': '{:.2f}%',\n    'hybrid_r2': '{:.4f}',\n    'training_time_sec': '{:.1f}s'\n}))\n\n# Calculate improvements\nprint(\"\\n\" + \"=\"*70)\nprint(\"HYBRID IMPROVEMENTS\")\nprint(\"=\"*70)\n\nfor idx, row in benchmark_df.iterrows():\n    prophet_imp = ((row['prophet_mae'] - row['hybrid_mae']) / row['prophet_mae']) * 100\n    \n    print(f\"\\n{row['resolution']} | {row['target']}:\")\n    print(f\"  Hybrid MAE: {row['hybrid_mae']:.2f}\")\n    print(f\"  Improvement over Prophet: {prophet_imp:+.1f}%\")\n    print(f\"  Improvement over LSTM: {lstm_imp:+.1f}%\")\n    # print(f\"  Anomaly rate: {row['anomaly_rate']:.2f}%\")\n\n# Overall statistics\nprint(\"\\n\" + \"=\"*70)\nprint(\"OVERALL STATISTICS\")\nprint(\"=\"*70)\n\navg_prophet_imp = ((benchmark_df['prophet_mae'] - benchmark_df['hybrid_mae']) / benchmark_df['prophet_mae']).mean() * 100\n\nprint(f\"\\nAverage Hybrid Improvement:\")\nprint(f\"  vs Prophet: {avg_prophet_imp:+.1f}%\")\n# print(f\"\\nAverage Anomaly Rate: {benchmark_df['anomaly_rate'].mean():.2f}%\")\n# print(f\"Total Anomalies Detected: {benchmark_df['anomalies_detected'].sum():,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:28:18.562252Z","iopub.execute_input":"2026-02-02T13:28:18.562584Z","iopub.status.idle":"2026-02-02T13:28:18.586509Z","shell.execute_reply.started":"2026-02-02T13:28:18.562559Z","shell.execute_reply":"2026-02-02T13:28:18.585727Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nGENERATING COMPREHENSIVE BENCHMARK\n======================================================================\n\nâœ“ Benchmark saved: /kaggle/working//FINAL_BENCHMARK/comprehensive_comparison.csv\n\nðŸ“Š BENCHMARK RESULTS:\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x79ccd085d610>","text/html":"<style type=\"text/css\">\n#T_4795f_row0_col2, #T_4795f_row0_col7, #T_4795f_row0_col8, #T_4795f_row2_col2, #T_4795f_row2_col7, #T_4795f_row2_col8 {\n  background-color: #006837;\n  color: #f1f1f1;\n}\n#T_4795f_row1_col2 {\n  background-color: #cbe982;\n  color: #000000;\n}\n#T_4795f_row1_col7 {\n  background-color: #e0f295;\n  color: #000000;\n}\n#T_4795f_row1_col8 {\n  background-color: #e2f397;\n  color: #000000;\n}\n#T_4795f_row3_col2, #T_4795f_row3_col7, #T_4795f_row3_col8 {\n  background-color: #a50026;\n  color: #f1f1f1;\n}\n</style>\n<table id=\"T_4795f\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_4795f_level0_col0\" class=\"col_heading level0 col0\" >resolution</th>\n      <th id=\"T_4795f_level0_col1\" class=\"col_heading level0 col1\" >target</th>\n      <th id=\"T_4795f_level0_col2\" class=\"col_heading level0 col2\" >prophet_mae</th>\n      <th id=\"T_4795f_level0_col3\" class=\"col_heading level0 col3\" >prophet_rmse</th>\n      <th id=\"T_4795f_level0_col4\" class=\"col_heading level0 col4\" >prophet_mse</th>\n      <th id=\"T_4795f_level0_col5\" class=\"col_heading level0 col5\" >prophet_mape</th>\n      <th id=\"T_4795f_level0_col6\" class=\"col_heading level0 col6\" >prophet_r2</th>\n      <th id=\"T_4795f_level0_col7\" class=\"col_heading level0 col7\" >hybrid_mae</th>\n      <th id=\"T_4795f_level0_col8\" class=\"col_heading level0 col8\" >hybrid_rmse</th>\n      <th id=\"T_4795f_level0_col9\" class=\"col_heading level0 col9\" >hybrid_mse</th>\n      <th id=\"T_4795f_level0_col10\" class=\"col_heading level0 col10\" >hybrid_mape</th>\n      <th id=\"T_4795f_level0_col11\" class=\"col_heading level0 col11\" >hybrid_r2</th>\n      <th id=\"T_4795f_level0_col12\" class=\"col_heading level0 col12\" >results_dir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_4795f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_4795f_row0_col0\" class=\"data row0 col0\" >5min</td>\n      <td id=\"T_4795f_row0_col1\" class=\"data row0 col1\" >request_count</td>\n      <td id=\"T_4795f_row0_col2\" class=\"data row0 col2\" >57.08</td>\n      <td id=\"T_4795f_row0_col3\" class=\"data row0 col3\" >81.34</td>\n      <td id=\"T_4795f_row0_col4\" class=\"data row0 col4\" >6615.84</td>\n      <td id=\"T_4795f_row0_col5\" class=\"data row0 col5\" >36.60%</td>\n      <td id=\"T_4795f_row0_col6\" class=\"data row0 col6\" >0.5584</td>\n      <td id=\"T_4795f_row0_col7\" class=\"data row0 col7\" >34.96</td>\n      <td id=\"T_4795f_row0_col8\" class=\"data row0 col8\" >46.99</td>\n      <td id=\"T_4795f_row0_col9\" class=\"data row0 col9\" >2208.31</td>\n      <td id=\"T_4795f_row0_col10\" class=\"data row0 col10\" >27.71%</td>\n      <td id=\"T_4795f_row0_col11\" class=\"data row0 col11\" >0.8526</td>\n      <td id=\"T_4795f_row0_col12\" class=\"data row0 col12\" >/kaggle/working//5min_request_count_setup1_replica</td>\n    </tr>\n    <tr>\n      <th id=\"T_4795f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_4795f_row1_col0\" class=\"data row1 col0\" >5min</td>\n      <td id=\"T_4795f_row1_col1\" class=\"data row1 col1\" >total_bytes</td>\n      <td id=\"T_4795f_row1_col2\" class=\"data row1 col2\" >928196.66</td>\n      <td id=\"T_4795f_row1_col3\" class=\"data row1 col3\" >1289904.19</td>\n      <td id=\"T_4795f_row1_col4\" class=\"data row1 col4\" >1663852821668.35</td>\n      <td id=\"T_4795f_row1_col5\" class=\"data row1 col5\" >38.37%</td>\n      <td id=\"T_4795f_row1_col6\" class=\"data row1 col6\" >0.3530</td>\n      <td id=\"T_4795f_row1_col7\" class=\"data row1 col7\" >632106.99</td>\n      <td id=\"T_4795f_row1_col8\" class=\"data row1 col8\" >847233.17</td>\n      <td id=\"T_4795f_row1_col9\" class=\"data row1 col9\" >717804046790.15</td>\n      <td id=\"T_4795f_row1_col10\" class=\"data row1 col10\" >29.33%</td>\n      <td id=\"T_4795f_row1_col11\" class=\"data row1 col11\" >0.7209</td>\n      <td id=\"T_4795f_row1_col12\" class=\"data row1 col12\" >/kaggle/working//5min_total_bytes_setup1_replica</td>\n    </tr>\n    <tr>\n      <th id=\"T_4795f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_4795f_row2_col0\" class=\"data row2 col0\" >15min</td>\n      <td id=\"T_4795f_row2_col1\" class=\"data row2 col1\" >request_count</td>\n      <td id=\"T_4795f_row2_col2\" class=\"data row2 col2\" >154.81</td>\n      <td id=\"T_4795f_row2_col3\" class=\"data row2 col3\" >226.28</td>\n      <td id=\"T_4795f_row2_col4\" class=\"data row2 col4\" >51201.37</td>\n      <td id=\"T_4795f_row2_col5\" class=\"data row2 col5\" >24.46%</td>\n      <td id=\"T_4795f_row2_col6\" class=\"data row2 col6\" >0.5933</td>\n      <td id=\"T_4795f_row2_col7\" class=\"data row2 col7\" >83.81</td>\n      <td id=\"T_4795f_row2_col8\" class=\"data row2 col8\" >114.77</td>\n      <td id=\"T_4795f_row2_col9\" class=\"data row2 col9\" >13171.50</td>\n      <td id=\"T_4795f_row2_col10\" class=\"data row2 col10\" >16.03%</td>\n      <td id=\"T_4795f_row2_col11\" class=\"data row2 col11\" >0.8954</td>\n      <td id=\"T_4795f_row2_col12\" class=\"data row2 col12\" >/kaggle/working//15min_request_count_setup1_replica</td>\n    </tr>\n    <tr>\n      <th id=\"T_4795f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_4795f_row3_col0\" class=\"data row3 col0\" >15min</td>\n      <td id=\"T_4795f_row3_col1\" class=\"data row3 col1\" >total_bytes</td>\n      <td id=\"T_4795f_row3_col2\" class=\"data row3 col2\" >2491716.33</td>\n      <td id=\"T_4795f_row3_col3\" class=\"data row3 col3\" >3485437.97</td>\n      <td id=\"T_4795f_row3_col4\" class=\"data row3 col4\" >12148277865859.69</td>\n      <td id=\"T_4795f_row3_col5\" class=\"data row3 col5\" >30.77%</td>\n      <td id=\"T_4795f_row3_col6\" class=\"data row3 col6\" >0.3990</td>\n      <td id=\"T_4795f_row3_col7\" class=\"data row3 col7\" >1502758.73</td>\n      <td id=\"T_4795f_row3_col8\" class=\"data row3 col8\" >1998017.18</td>\n      <td id=\"T_4795f_row3_col9\" class=\"data row3 col9\" >3992072664394.16</td>\n      <td id=\"T_4795f_row3_col10\" class=\"data row3 col10\" >22.56%</td>\n      <td id=\"T_4795f_row3_col11\" class=\"data row3 col11\" >0.8025</td>\n      <td id=\"T_4795f_row3_col12\" class=\"data row3 col12\" >/kaggle/working//15min_total_bytes_setup1_replica</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}},{"name":"stdout","text":"\n======================================================================\nHYBRID IMPROVEMENTS\n======================================================================\n\n5min | request_count:\n  Hybrid MAE: 34.96\n  Improvement over Prophet: +38.8%\n  Improvement over LSTM: +0.0%\n\n5min | total_bytes:\n  Hybrid MAE: 632106.99\n  Improvement over Prophet: +31.9%\n  Improvement over LSTM: +0.0%\n\n15min | request_count:\n  Hybrid MAE: 83.81\n  Improvement over Prophet: +45.9%\n  Improvement over LSTM: +0.0%\n\n15min | total_bytes:\n  Hybrid MAE: 1502758.73\n  Improvement over Prophet: +39.7%\n  Improvement over LSTM: +0.0%\n\n======================================================================\nOVERALL STATISTICS\n======================================================================\n\nAverage Hybrid Improvement:\n  vs Prophet: +39.1%\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"# ===========================\n# CELL 10: SUMMARY & NEXT STEPS\n# ===========================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ðŸŽ‰ AUTOMATED HYBRID PIPELINE COMPLETED SUCCESSFULLY!\")\nprint(\"=\"*80)\n\nprint(f\"\\nðŸ“Š SUMMARY:\")\nprint(f\"  Total configurations: {len(all_results)}\")\nprint(f\"  Total time: {total_elapsed/60:.1f} minutes\")\nprint(f\"  Average time per config: {total_elapsed/len(all_results):.1f} seconds\")\n\nprint(f\"\\nðŸ“ RESULTS LOCATION:\")\nprint(f\"  Main directory: {RESULTS_BASE_DIR}\")\nprint(f\"  Benchmark: {benchmark_dir}\")\n\nprint(f\"\\nðŸ† BEST CONFIGURATION:\")\nprint(f\"  {best['resolution']} | {best['target']}\")\nprint(f\"  Hybrid MAE: {best['hybrid_mae']:.2f}\")\nprint(f\"  Improvement: {avg_prophet_imp:+.1f}% vs Prophet, {avg_lstm_imp:+.1f}% vs LSTM\")\n\n# print(f\"\\nðŸ” ANOMALY DETECTION:\")\n# print(f\"  Total anomalies: {benchmark_df['anomalies_detected'].sum():,}\")\n# print(f\"  Average rate: {benchmark_df['anomaly_rate'].mean():.2f}%\")\n\nprint(f\"\\nðŸ“ˆ TOP 3 PERFORMERS (by Hybrid MAE):\")\ntop_3 = benchmark_df.nsmallest(3, 'hybrid_mae')[['resolution', 'target', 'hybrid_mae', 'hybrid_rmse']]\nfor idx, row in top_3.iterrows():\n    print(f\"  {row['resolution']:5s} | {row['target']:15s} | MAE: {row['hybrid_mae']:6.2f} | RMSE: {row['hybrid_rmse']:6.2f}\")\n\nprint(f\"\\nðŸ’¡ NEXT STEPS:\")\nprint(f\"  1. Review final_report.txt in {benchmark_dir}\")\nprint(f\"  2. Check benchmark_visualizations.png\")\nprint(f\"  3. Analyze anomalies.csv for each configuration\")\nprint(f\"  4. Deploy best hybrid model to production\")\nprint(f\"  5. Set up monitoring for anomaly alerts\")\nprint(f\"  6. Implement retraining pipeline (weekly Prophet, daily LSTM)\")\n\nprint(f\"\\n\" + \"=\"*80)\nprint(\"All results have been saved to Google Drive!\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:40:58.578594Z","iopub.execute_input":"2026-02-02T13:40:58.578890Z","iopub.status.idle":"2026-02-02T13:40:58.591362Z","shell.execute_reply.started":"2026-02-02T13:40:58.578865Z","shell.execute_reply":"2026-02-02T13:40:58.590743Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nðŸŽ‰ AUTOMATED HYBRID PIPELINE COMPLETED SUCCESSFULLY!\n================================================================================\n\nðŸ“Š SUMMARY:\n  Total configurations: 4\n  Total time: 4.6 minutes\n  Average time per config: 69.2 seconds\n\nðŸ“ RESULTS LOCATION:\n  Main directory: /kaggle/working/\n  Benchmark: /kaggle/working//FINAL_BENCHMARK\n\nðŸ† BEST CONFIGURATION:\n  5min | request_count\n  Hybrid MAE: 34.96\n  Improvement: +39.1% vs Prophet, -0.0% vs LSTM\n\nðŸ“ˆ TOP 3 PERFORMERS (by Hybrid MAE):\n  5min  | request_count   | MAE:  34.96 | RMSE:  46.99\n  15min | request_count   | MAE:  83.81 | RMSE: 114.77\n  5min  | total_bytes     | MAE: 632106.99 | RMSE: 847233.17\n\nðŸ’¡ NEXT STEPS:\n  1. Review final_report.txt in /kaggle/working//FINAL_BENCHMARK\n  2. Check benchmark_visualizations.png\n  3. Analyze anomalies.csv for each configuration\n  4. Deploy best hybrid model to production\n  5. Set up monitoring for anomaly alerts\n  6. Implement retraining pipeline (weekly Prophet, daily LSTM)\n\n================================================================================\nAll results have been saved to Google Drive!\n================================================================================\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"# NÃ©n toÃ n bá»™ file trong thÆ° má»¥c hiá»‡n táº¡i (recursive)\n!zip -r all_output.zip .\n\n# Táº¡o link táº£i\nfrom IPython.display import FileLink\nFileLink('all_output.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T13:41:09.641187Z","iopub.execute_input":"2026-02-02T13:41:09.641934Z","iopub.status.idle":"2026-02-02T13:41:09.941594Z","shell.execute_reply.started":"2026-02-02T13:41:09.641905Z","shell.execute_reply":"2026-02-02T13:41:09.940861Z"}},"outputs":[{"name":"stdout","text":"updating: 5min_request_count_raw_no_log/ (stored 0%)\nupdating: 5min_request_count_raw_no_log/prophet_model/ (stored 0%)\nupdating: 15min_request_count_raw_no_log/ (stored 0%)\nupdating: 15min_request_count_raw_no_log/prophet_model/ (stored 0%)\nupdating: 5min_request_count_final/ (stored 0%)\nupdating: 5min_request_count_final/prophet_model/ (stored 0%)\nupdating: .virtual_documents/ (stored 0%)\nupdating: .virtual_documents/__notebook_source__.ipynb (deflated 80%)\nupdating: 5min_total_bytes_raw_no_log/ (stored 0%)\nupdating: 5min_total_bytes_raw_no_log/prophet_model/ (stored 0%)\nupdating: 15min_total_bytes_raw_no_log/ (stored 0%)\nupdating: 15min_total_bytes_raw_no_log/prophet_model/ (stored 0%)\nupdating: FINAL_BENCHMARK/ (stored 0%)\nupdating: FINAL_BENCHMARK/final_report.txt (deflated 67%)\nupdating: FINAL_BENCHMARK/comprehensive_comparison.csv (deflated 50%)\nupdating: FINAL_BENCHMARK/benchmark_visualizations.png (deflated 16%)\nupdating: 5min_total_bytes_final/ (stored 0%)\nupdating: 5min_total_bytes_final/prophet_model/ (stored 0%)\n  adding: 15min_request_count_setup1_replica/ (stored 0%)\n  adding: 15min_request_count_setup1_replica/prophet_model/ (stored 0%)\n  adding: 15min_request_count_setup1_replica/hybrid_predictions.csv (deflated 59%)\n  adding: 15min_request_count_setup1_revival/ (stored 0%)\n  adding: 15min_request_count_setup1_revival/prophet_model/ (stored 0%)\n  adding: 15min_request_count_setup1_revival/hybrid_predictions.csv (deflated 59%)\n  adding: 15min_request_count_upgrade/ (stored 0%)\n  adding: 15min_request_count_upgrade/prophet_model/ (stored 0%)\n  adding: 15min_request_count_upgrade/hybrid_predictions.csv (deflated 56%)\n  adding: 5min_request_count_setup1_replica/ (stored 0%)\n  adding: 5min_request_count_setup1_replica/prophet_model/ (stored 0%)\n  adding: 5min_request_count_setup1_replica/hybrid_predictions.csv (deflated 61%)\n  adding: 15min_total_bytes_setup1_revival/ (stored 0%)\n  adding: 15min_total_bytes_setup1_revival/prophet_model/ (stored 0%)\n  adding: 15min_total_bytes_setup1_revival/hybrid_predictions.csv (deflated 60%)\n  adding: 5min_request_count_rolling/ (stored 0%)\n  adding: 5min_request_count_rolling/prophet_model/ (stored 0%)\n  adding: 5min_request_count_upgrade/ (stored 0%)\n  adding: 5min_request_count_upgrade/prophet_model/ (stored 0%)\n  adding: 5min_request_count_upgrade/hybrid_predictions.csv (deflated 58%)\n  adding: 5min_total_bytes_setup1_revival/ (stored 0%)\n  adding: 5min_total_bytes_setup1_revival/prophet_model/ (stored 0%)\n  adding: 5min_total_bytes_setup1_revival/hybrid_predictions.csv (deflated 60%)\n  adding: 5min_request_count_setup1_revival/ (stored 0%)\n  adding: 5min_request_count_setup1_revival/prophet_model/ (stored 0%)\n  adding: 5min_request_count_setup1_revival/hybrid_predictions.csv (deflated 61%)\n  adding: 15min_request_count_rolling/ (stored 0%)\n  adding: 15min_request_count_rolling/prophet_model/ (stored 0%)\n  adding: 15min_total_bytes_setup1_replica/ (stored 0%)\n  adding: 15min_total_bytes_setup1_replica/prophet_model/ (stored 0%)\n  adding: 15min_total_bytes_setup1_replica/hybrid_predictions.csv (deflated 60%)\n  adding: 15min_total_bytes_upgrade/ (stored 0%)\n  adding: 15min_total_bytes_upgrade/prophet_model/ (stored 0%)\n  adding: 15min_total_bytes_upgrade/hybrid_predictions.csv (deflated 56%)\n  adding: 5min_total_bytes_rolling/ (stored 0%)\n  adding: 5min_total_bytes_rolling/prophet_model/ (stored 0%)\n  adding: 5min_total_bytes_upgrade/ (stored 0%)\n  adding: 5min_total_bytes_upgrade/prophet_model/ (stored 0%)\n  adding: 5min_total_bytes_upgrade/hybrid_predictions.csv (deflated 57%)\n  adding: 5min_total_bytes_setup1_replica/ (stored 0%)\n  adding: 5min_total_bytes_setup1_replica/prophet_model/ (stored 0%)\n  adding: 5min_total_bytes_setup1_replica/hybrid_predictions.csv (deflated 60%)\n","output_type":"stream"},{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/all_output.zip","text/html":"<a href='all_output.zip' target='_blank'>all_output.zip</a><br>"},"metadata":{}}],"execution_count":86}]}