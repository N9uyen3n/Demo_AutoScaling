{"cells":[{"cell_type":"markdown","metadata":{"id":"5hiizOjzGKhc"},"source":["# üîÆ PROPHET AUTOMATED TRAINING PIPELINE\n","## Comprehensive Multi-Resolution Forecasting with Auto-Benchmark\n","\n","### üöÄ AUTO-RUN CONFIGURATION:\n","**Just click \"Run All\" and the notebook will automatically:**\n","1. Train Prophet models for ALL resolutions (1min, 5min, 15min)\n","2. Forecast BOTH targets (request_count, total_bytes)\n","3. Perform hyperparameter tuning for each configuration\n","4. Generate comprehensive benchmarks\n","5. Save all predictions and parameters\n","6. Create comparative visualizations\n","\n","### üìä Total Configurations:\n","- **3 resolutions** √ó **2 targets** = **6 model trainings**\n","- Each with hyperparameter tuning\n","- Expected runtime: **20-40 minutes** (CPU)\n","\n","### üìÅ Output Structure:\n","```\n","RESULTS_PROPHET/\n","‚îú‚îÄ‚îÄ 1min_request_count/\n","‚îÇ   ‚îú‚îÄ‚îÄ predictions.csv\n","‚îÇ   ‚îú‚îÄ‚îÄ metrics.csv\n","‚îÇ   ‚îú‚îÄ‚îÄ best_parameters.csv\n","‚îÇ   ‚îî‚îÄ‚îÄ evaluation.png\n","‚îú‚îÄ‚îÄ 1min_total_bytes/\n","‚îú‚îÄ‚îÄ 5min_request_count/\n","‚îú‚îÄ‚îÄ ... (6 configurations total)\n","‚îî‚îÄ‚îÄ FINAL_BENCHMARK/\n","    ‚îú‚îÄ‚îÄ comprehensive_comparison.csv\n","    ‚îú‚îÄ‚îÄ final_report.txt\n","    ‚îî‚îÄ‚îÄ benchmark_visualizations.png\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SajzVUNQGKhg"},"outputs":[],"source":["# ===========================\n","# CELL 1: MOUNT GOOGLE DRIVE\n","# ===========================\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","print(\"‚úì Google Drive mounted successfully\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecASPPQ0GKhh"},"outputs":[],"source":["# ===========================\n","# CELL 2: SETUP & INSTALLATIONS\n","# ===========================\n","\n","!pip install prophet scikit-learn -q\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","import warnings\n","warnings.filterwarnings('ignore')\n","import os\n","from datetime import datetime\n","import time\n","from typing import Dict, List\n","\n","# Prophet\n","from prophet import Prophet\n","\n","# Set seeds\n","np.random.seed(42)\n","\n","# Visualization\n","plt.style.use('seaborn-v0_8-whitegrid')\n","sns.set_palette(\"husl\")\n","plt.rcParams['figure.figsize'] = (18, 6)\n","\n","print(\"=\"*70)\n","print(\"PROPHET AUTOMATED TRAINING PIPELINE\")\n","print(\"=\"*70)\n","print(f\"  Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n","print(\"=\"*70)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4J-JDMgGKhh"},"outputs":[],"source":["# ===========================\n","# CELL 3: GLOBAL CONFIGURATION\n","# ===========================\n","\n","# Paths\n","DATA_DIR = '/content/drive/MyDrive/AUTOSCALING ANALYSIS/PROCESSED_DATAFINAL'\n","RESULTS_BASE_DIR = '/content/drive/MyDrive/AUTOSCALING ANALYSIS/RESULTS_PROPHET'\n","\n","# Create base results directory\n","os.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n","\n","# All configurations to run\n","RESOLUTIONS = ['1min', '5min', '15min']\n","TARGETS = ['request_count', 'total_bytes']\n","\n","# Hyperparameter search space\n","PARAM_GRID = {\n","    'changepoint_prior_scale': [0.5, 1, 5, 10],\n","    'seasonality_prior_scale': [1, 10, 30, 50],\n","    'seasonality_mode': ['additive', 'multiplicative']\n","}\n","\n","# Storm/outage holiday (adjust dates if needed)\n","STORM_HOLIDAY = pd.DataFrame({\n","    'holiday': 'storm_outage',\n","    'ds': pd.date_range(start='1995-08-01 14:52:01', end='1995-08-03 04:36:13', freq='h'),\n","    'lower_window': 0,\n","    'upper_window': 0,\n","})\n","\n","print(\"\\nüìã CONFIGURATION LOADED:\")\n","print(f\"  Resolutions: {RESOLUTIONS}\")\n","print(f\"  Targets: {TARGETS}\")\n","print(f\"  Total configurations: {len(RESOLUTIONS) * len(TARGETS)}\")\n","print(f\"  Hyperparameter combinations: {len(PARAM_GRID['changepoint_prior_scale']) * len(PARAM_GRID['seasonality_prior_scale']) * len(PARAM_GRID['seasonality_mode'])}\")\n","print(f\"\\n  Data directory: {DATA_DIR}\")\n","print(f\"  Results directory: {RESULTS_BASE_DIR}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VHLBGshGKhi"},"outputs":[],"source":["# ===========================\n","# CELL 4: UTILITY FUNCTIONS\n","# ===========================\n","\n","def prepare_prophet_data(df, target_col):\n","    \"\"\"\n","    Prepare data for Prophet.\n","    \"\"\"\n","    prophet_df = pd.DataFrame({\n","        'ds': df.index,\n","        'y': df[target_col]\n","    })\n","\n","    # Add time-based features (always known in future)\n","    prophet_df['hour'] = prophet_df['ds'].dt.hour\n","    prophet_df['day_of_week'] = prophet_df['ds'].dt.dayofweek\n","    prophet_df['is_weekend'] = (prophet_df['day_of_week'] >= 5).astype(int)\n","\n","    return prophet_df\n","\n","\n","def calculate_metrics(y_true, y_pred, model_name=\"Model\"):\n","    \"\"\"\n","    Calculate comprehensive metrics.\n","    \"\"\"\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","\n","    # MAPE (avoid division by zero)\n","    mask = y_true != 0\n","    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else 0\n","\n","    # R¬≤\n","    r2 = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_true.mean())**2))\n","\n","    metrics = {\n","        'Model': model_name,\n","        'MAE': mae,\n","        'MSE': mse,\n","        'RMSE': rmse,\n","        'MAPE (%)': mape,\n","        'R¬≤': r2\n","    }\n","\n","    return metrics\n","\n","\n","def tune_prophet_hyperparameters(train_data, param_grid, verbose=False):\n","    \"\"\"\n","    Perform grid search for Prophet hyperparameters.\n","    \"\"\"\n","    # Use subset for validation\n","    val_size = int(len(train_data) * 0.2)\n","    train_subset = train_data[:-val_size]\n","    val_subset = train_data[-val_size:]\n","\n","    best_params = None\n","    best_mae = float('inf')\n","    results = []\n","\n","    total_combinations = len(param_grid['changepoint_prior_scale']) * \\\n","                        len(param_grid['seasonality_prior_scale']) * \\\n","                        len(param_grid['seasonality_mode'])\n","\n","    if verbose:\n","        print(f\"    Testing {total_combinations} parameter combinations...\")\n","\n","    counter = 0\n","    for cp_scale in param_grid['changepoint_prior_scale']:\n","        for s_scale in param_grid['seasonality_prior_scale']:\n","            for s_mode in param_grid['seasonality_mode']:\n","                counter += 1\n","\n","                try:\n","                    model = Prophet(\n","                        daily_seasonality=True,\n","                        weekly_seasonality=True,\n","                        yearly_seasonality=False,\n","                        changepoint_prior_scale=cp_scale,\n","                        seasonality_prior_scale=s_scale,\n","                        seasonality_mode=s_mode,\n","                        holidays=STORM_HOLIDAY\n","                    )\n","\n","                    model.add_regressor('hour')\n","                    model.add_regressor('day_of_week')\n","                    model.add_regressor('is_weekend')\n","\n","                    model.fit(train_subset)\n","\n","                    forecast = model.predict(val_subset[['ds', 'hour', 'day_of_week', 'is_weekend']])\n","                    mae = mean_absolute_error(val_subset['y'], forecast['yhat'])\n","\n","                    results.append({\n","                        'changepoint_prior_scale': cp_scale,\n","                        'seasonality_prior_scale': s_scale,\n","                        'seasonality_mode': s_mode,\n","                        'mae': mae\n","                    })\n","\n","                    if mae < best_mae:\n","                        best_mae = mae\n","                        best_params = {\n","                            'changepoint_prior_scale': cp_scale,\n","                            'seasonality_prior_scale': s_scale,\n","                            'seasonality_mode': s_mode\n","                        }\n","\n","                except Exception as e:\n","                    if verbose:\n","                        print(f\"      Error with params {counter}/{total_combinations}: {str(e)}\")\n","\n","    return best_params, best_mae, pd.DataFrame(results)\n","\n","\n","print(\"‚úì Utility functions defined\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7qblC8uGKhi"},"outputs":[],"source":["# ===========================\n","# CELL 5: MAIN TRAINING FUNCTION\n","# ===========================\n","\n","def train_single_configuration(resolution, target, verbose=True):\n","    \"\"\"\n","    Train a single Prophet model configuration and return results.\n","    \"\"\"\n","    if verbose:\n","        print(f\"\\n{'='*70}\")\n","        print(f\"TRAINING: Prophet | {resolution} | {target}\")\n","        print(f\"{'='*70}\")\n","\n","    start_time = time.time()\n","\n","    # Create results directory\n","    results_dir = f\"{RESULTS_BASE_DIR}/{resolution}_{target}\"\n","    os.makedirs(results_dir, exist_ok=True)\n","\n","    try:\n","        # Load data\n","        if verbose:\n","            print(f\"\\n[1/5] Loading data...\")\n","        train_df = pd.read_csv(f\"{DATA_DIR}/train_{resolution}.csv\", index_col=0, parse_dates=True)\n","        test_df = pd.read_csv(f\"{DATA_DIR}/test_{resolution}.csv\", index_col=0, parse_dates=True)\n","\n","        # Prepare Prophet data\n","        if verbose:\n","            print(f\"[2/5] Preparing Prophet data...\")\n","        prophet_train = prepare_prophet_data(train_df, target)\n","        prophet_test = prepare_prophet_data(test_df, target)\n","\n","        if verbose:\n","            print(f\"    Train: {len(prophet_train):,} rows, Test: {len(prophet_test):,} rows\")\n","\n","        # Hyperparameter tuning\n","        if verbose:\n","            print(f\"[3/5] Tuning hyperparameters...\")\n","        best_params, best_mae, tuning_results = tune_prophet_hyperparameters(\n","            prophet_train, PARAM_GRID, verbose=verbose\n","        )\n","\n","        if verbose:\n","            print(f\"    Best MAE: {best_mae:.2f}\")\n","            print(f\"    Best params: cp={best_params['changepoint_prior_scale']}, \"\n","                  f\"s={best_params['seasonality_prior_scale']}, mode={best_params['seasonality_mode']}\")\n","\n","        # Save tuning results\n","        tuning_results.to_csv(f\"{results_dir}/hyperparameter_tuning.csv\", index=False)\n","\n","        # Train final model with best parameters\n","        if verbose:\n","            print(f\"[4/5] Training final model...\")\n","\n","        model = Prophet(\n","            daily_seasonality=True,\n","            weekly_seasonality=True,\n","            yearly_seasonality=False,\n","            changepoint_prior_scale=best_params['changepoint_prior_scale'],\n","            seasonality_prior_scale=best_params['seasonality_prior_scale'],\n","            seasonality_mode=best_params['seasonality_mode'],\n","            holidays=STORM_HOLIDAY\n","        )\n","\n","        # Add custom seasonalities based on resolution\n","        if resolution == '1min':\n","            model.add_seasonality(name='hourly_pattern', period=1/24, fourier_order=10)\n","        elif resolution == '5min':\n","            model.add_seasonality(name='daily_high_freq', period=1, fourier_order=50)\n","            model.add_seasonality(name='weekly_high_freq', period=7, fourier_order=20)\n","        else:  # 15min\n","            model.add_seasonality(name='daily_pattern', period=1, fourier_order=25)\n","\n","        model.add_regressor('hour')\n","        model.add_regressor('day_of_week')\n","        model.add_regressor('is_weekend')\n","\n","        model.fit(prophet_train)\n","\n","        # Predict\n","        if verbose:\n","            print(f\"[5/5] Evaluating...\")\n","\n","        future = prophet_test[['ds', 'hour', 'day_of_week', 'is_weekend']].copy()\n","        forecast = model.predict(future)\n","\n","        # Calculate metrics\n","        y_true = prophet_test['y'].values\n","        y_pred = forecast['yhat'].values\n","\n","        metrics = calculate_metrics(y_true, y_pred, \"Prophet\")\n","\n","        if verbose:\n","            print(f\"    MAE: {metrics['MAE']:.2f}, RMSE: {metrics['RMSE']:.2f}, MAPE: {metrics['MAPE (%)']:.2f}%\")\n","\n","        # Prediction interval coverage\n","        lower = forecast['yhat_lower'].values\n","        upper = forecast['yhat_upper'].values\n","        within_interval = np.sum((y_true >= lower) & (y_true <= upper))\n","        coverage = (within_interval / len(y_true)) * 100\n","\n","        # Save results\n","        # Predictions\n","        predictions_df = pd.DataFrame({\n","            'timestamp': prophet_test['ds'],\n","            'actual': y_true,\n","            'predicted': y_pred,\n","            'lower_bound': lower,\n","            'upper_bound': upper,\n","            'residual': y_true - y_pred\n","        })\n","        predictions_df.to_csv(f\"{results_dir}/predictions.csv\", index=False)\n","\n","        # Metrics\n","        metrics_df = pd.DataFrame([metrics])\n","        metrics_df.to_csv(f\"{results_dir}/metrics.csv\", index=False)\n","\n","        # Best parameters\n","        params_df = pd.DataFrame([{\n","            'changepoint_prior_scale': best_params['changepoint_prior_scale'],\n","            'seasonality_prior_scale': best_params['seasonality_prior_scale'],\n","            'seasonality_mode': best_params['seasonality_mode'],\n","            'daily_seasonality': True,\n","            'weekly_seasonality': True,\n","            'yearly_seasonality': False,\n","            'interval_coverage': coverage\n","        }])\n","        params_df.to_csv(f\"{results_dir}/best_parameters.csv\", index=False)\n","\n","        # Full forecast\n","        forecast.to_csv(f\"{results_dir}/forecast_full.csv\", index=False)\n","\n","        # Training time\n","        elapsed_time = time.time() - start_time\n","\n","        if verbose:\n","            print(f\"\\n‚úì Completed in {elapsed_time:.1f} seconds\")\n","            print(f\"  Results saved to: {results_dir}\")\n","\n","        # Return results for benchmark\n","        return {\n","            'resolution': resolution,\n","            'target': target,\n","            'mae': metrics['MAE'],\n","            'mse': metrics['MSE'],\n","            'rmse': metrics['RMSE'],\n","            'mape': metrics['MAPE (%)'],\n","            'r2': metrics['R¬≤'],\n","            'interval_coverage': coverage,\n","            'changepoint_prior_scale': best_params['changepoint_prior_scale'],\n","            'seasonality_prior_scale': best_params['seasonality_prior_scale'],\n","            'seasonality_mode': best_params['seasonality_mode'],\n","            'training_time_sec': elapsed_time,\n","            'results_dir': results_dir\n","        }\n","\n","    except Exception as e:\n","        print(f\"\\n‚ùå ERROR: {str(e)}\")\n","        import traceback\n","        traceback.print_exc()\n","        return None\n","\n","\n","print(\"‚úì Training function defined\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvGFIJ9yGKhj"},"outputs":[],"source":["# ===========================\n","# CELL 6: RUN ALL CONFIGURATIONS\n","# ===========================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"STARTING AUTOMATED TRAINING PIPELINE\")\n","print(\"=\"*70)\n","\n","all_results = []\n","total_configs = len(RESOLUTIONS) * len(TARGETS)\n","current_config = 0\n","\n","pipeline_start_time = time.time()\n","\n","for resolution in RESOLUTIONS:\n","    for target in TARGETS:\n","        current_config += 1\n","\n","        print(f\"\\n\\n{'#'*70}\")\n","        print(f\"CONFIGURATION {current_config}/{total_configs}\")\n","        print(f\"{'#'*70}\")\n","\n","        result = train_single_configuration(resolution, target, verbose=True)\n","\n","        if result is not None:\n","            all_results.append(result)\n","            print(f\"\\n‚úÖ Configuration {current_config}/{total_configs} completed successfully\")\n","        else:\n","            print(f\"\\n‚ùå Configuration {current_config}/{total_configs} failed\")\n","\n","        # Progress update\n","        elapsed = time.time() - pipeline_start_time\n","        avg_time = elapsed / current_config\n","        remaining = (total_configs - current_config) * avg_time\n","\n","        print(f\"\\nüìä Progress: {current_config}/{total_configs} ({current_config/total_configs*100:.1f}%)\")\n","        print(f\"   Elapsed: {elapsed/60:.1f} min | Est. remaining: {remaining/60:.1f} min\")\n","\n","total_elapsed = time.time() - pipeline_start_time\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"ALL CONFIGURATIONS COMPLETED\")\n","print(\"=\"*70)\n","print(f\"  Total time: {total_elapsed/60:.1f} minutes\")\n","print(f\"  Successful: {len(all_results)}/{total_configs}\")\n","print(f\"  Failed: {total_configs - len(all_results)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ll1oKMBGKhj"},"outputs":[],"source":["# ===========================\n","# CELL 7: CREATE COMPREHENSIVE BENCHMARK\n","# ===========================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"GENERATING COMPREHENSIVE BENCHMARK\")\n","print(\"=\"*70)\n","\n","# Create benchmark directory\n","benchmark_dir = f\"{RESULTS_BASE_DIR}/FINAL_BENCHMARK\"\n","os.makedirs(benchmark_dir, exist_ok=True)\n","\n","# Convert results to DataFrame\n","benchmark_df = pd.DataFrame(all_results)\n","\n","# Save comprehensive comparison\n","benchmark_file = f\"{benchmark_dir}/comprehensive_comparison.csv\"\n","benchmark_df.to_csv(benchmark_file, index=False)\n","print(f\"\\n‚úì Benchmark saved: {benchmark_file}\")\n","\n","print(\"\\nüìä BENCHMARK RESULTS:\\n\")\n","display(benchmark_df.style.background_gradient(cmap='RdYlGn_r', subset=['mae', 'rmse', 'mape']).format({\n","    'mae': '{:.2f}',\n","    'rmse': '{:.2f}',\n","    'mape': '{:.2f}%',\n","    'r2': '{:.4f}',\n","    'interval_coverage': '{:.1f}%',\n","    'training_time_sec': '{:.1f}s'\n","}))\n","\n","# Find best configuration\n","print(\"\\n\" + \"=\"*70)\n","print(\"BEST CONFIGURATIONS\")\n","print(\"=\"*70)\n","\n","# By resolution\n","print(\"\\nBest by Resolution:\")\n","for resolution in RESOLUTIONS:\n","    subset = benchmark_df[benchmark_df['resolution'] == resolution]\n","    if len(subset) > 0:\n","        best_idx = subset['mae'].idxmin()\n","        best = subset.loc[best_idx]\n","        print(f\"  {resolution}: {best['target']} (MAE: {best['mae']:.2f}, MAPE: {best['mape']:.2f}%)\")\n","\n","# By target\n","print(\"\\nBest by Target:\")\n","for target in TARGETS:\n","    subset = benchmark_df[benchmark_df['target'] == target]\n","    if len(subset) > 0:\n","        best_idx = subset['mae'].idxmin()\n","        best = subset.loc[best_idx]\n","        print(f\"  {target}: {best['resolution']} (MAE: {best['mae']:.2f}, MAPE: {best['mape']:.2f}%)\")\n","\n","# Overall best\n","overall_best_idx = benchmark_df['mae'].idxmin()\n","overall_best = benchmark_df.loc[overall_best_idx]\n","print(f\"\\nOverall Best: {overall_best['resolution']} | {overall_best['target']}\")\n","print(f\"  MAE: {overall_best['mae']:.2f}\")\n","print(f\"  RMSE: {overall_best['rmse']:.2f}\")\n","print(f\"  MAPE: {overall_best['mape']:.2f}%\")\n","print(f\"  R¬≤: {overall_best['r2']:.4f}\")\n","print(f\"  Parameters: cp={overall_best['changepoint_prior_scale']}, s={overall_best['seasonality_prior_scale']}, mode={overall_best['seasonality_mode']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbQkYP2rGKhj"},"outputs":[],"source":["# ===========================\n","# CELL 8: BENCHMARK VISUALIZATIONS\n","# ===========================\n","\n","print(\"\\n[CREATING BENCHMARK VISUALIZATIONS]\\n\")\n","\n","fig = plt.figure(figsize=(20, 10))\n","gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n","\n","# 1. MAE by Resolution and Target\n","ax1 = fig.add_subplot(gs[0, :])\n","pivot_mae = benchmark_df.pivot_table(values='mae', index='resolution', columns='target')\n","pivot_mae.plot(kind='bar', ax=ax1, color=['#2a9d8f', '#e76f51'], alpha=0.8, width=0.6)\n","ax1.set_title('MAE Comparison Across All Configurations', fontweight='bold', fontsize=14)\n","ax1.set_ylabel('MAE')\n","ax1.set_xlabel('Resolution')\n","ax1.legend(title='Target')\n","ax1.grid(True, alpha=0.3, axis='y')\n","plt.setp(ax1.xaxis.get_majorticklabels(), rotation=0)\n","\n","# 2. MAPE Comparison\n","ax2 = fig.add_subplot(gs[1, 0])\n","pivot_mape = benchmark_df.pivot_table(values='mape', index='resolution', columns='target')\n","pivot_mape.plot(kind='bar', ax=ax2, color=['#2a9d8f', '#e76f51'], alpha=0.8)\n","ax2.set_title('MAPE by Configuration', fontweight='bold', fontsize=12)\n","ax2.set_ylabel('MAPE (%)')\n","ax2.set_xlabel('Resolution')\n","ax2.legend(title='Target')\n","ax2.grid(True, alpha=0.3, axis='y')\n","plt.setp(ax2.xaxis.get_majorticklabels(), rotation=0)\n","\n","# 3. R¬≤ Comparison\n","ax3 = fig.add_subplot(gs[1, 1])\n","pivot_r2 = benchmark_df.pivot_table(values='r2', index='resolution', columns='target')\n","pivot_r2.plot(kind='bar', ax=ax3, color=['#2a9d8f', '#e76f51'], alpha=0.8)\n","ax3.set_title('R¬≤ Score by Configuration', fontweight='bold', fontsize=12)\n","ax3.set_ylabel('R¬≤')\n","ax3.set_xlabel('Resolution')\n","ax3.legend(title='Target')\n","ax3.grid(True, alpha=0.3, axis='y')\n","plt.setp(ax3.xaxis.get_majorticklabels(), rotation=0)\n","\n","# 4. Interval Coverage\n","ax4 = fig.add_subplot(gs[1, 2])\n","pivot_coverage = benchmark_df.pivot_table(values='interval_coverage', index='resolution', columns='target')\n","pivot_coverage.plot(kind='bar', ax=ax4, color=['#2a9d8f', '#e76f51'], alpha=0.8)\n","ax4.axhline(y=95, color='red', linestyle='--', label='Expected 95%')\n","ax4.set_title('Prediction Interval Coverage', fontweight='bold', fontsize=12)\n","ax4.set_ylabel('Coverage (%)')\n","ax4.set_xlabel('Resolution')\n","ax4.legend()\n","ax4.grid(True, alpha=0.3, axis='y')\n","plt.setp(ax4.xaxis.get_majorticklabels(), rotation=0)\n","\n","plt.suptitle('Prophet: Comprehensive Benchmark Analysis',\n","            fontsize=16, fontweight='bold', y=0.995)\n","\n","viz_file = f\"{benchmark_dir}/benchmark_visualizations.png\"\n","plt.savefig(viz_file, dpi=150, bbox_inches='tight')\n","plt.show()\n","\n","print(f\"‚úì Visualizations saved: {viz_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06fYCrVnGKhk"},"outputs":[],"source":["# ===========================\n","# CELL 9: GENERATE FINAL REPORT\n","# ===========================\n","\n","print(\"\\n[GENERATING FINAL REPORT]\\n\")\n","\n","report = f\"\"\"\n","{'='*80}\n","PROPHET: COMPREHENSIVE BENCHMARK REPORT\n","{'='*80}\n","\n","Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n","Total Pipeline Time: {total_elapsed/60:.1f} minutes\n","\n","{'='*80}\n","CONFIGURATIONS TESTED\n","{'='*80}\n","\n","Resolutions: {', '.join(RESOLUTIONS)}\n","Target Variables: {', '.join(TARGETS)}\n","\n","Total Configurations: {total_configs}\n","Successful: {len(all_results)}\n","Failed: {total_configs - len(all_results)}\n","\n","Hyperparameter Search Space:\n","  changepoint_prior_scale: {PARAM_GRID['changepoint_prior_scale']}\n","  seasonality_prior_scale: {PARAM_GRID['seasonality_prior_scale']}\n","  seasonality_mode: {PARAM_GRID['seasonality_mode']}\n","\n","{'='*80}\n","OVERALL PERFORMANCE\n","{'='*80}\n","\n","Average Metrics:\n","  MAE:  {benchmark_df['mae'].mean():.2f} (¬±{benchmark_df['mae'].std():.2f})\n","  RMSE: {benchmark_df['rmse'].mean():.2f} (¬±{benchmark_df['rmse'].std():.2f})\n","  MAPE: {benchmark_df['mape'].mean():.2f}% (¬±{benchmark_df['mape'].std():.2f}%)\n","  R¬≤:   {benchmark_df['r2'].mean():.4f} (¬±{benchmark_df['r2'].std():.4f})\n","  Interval Coverage: {benchmark_df['interval_coverage'].mean():.1f}% (¬±{benchmark_df['interval_coverage'].std():.1f}%)\n","  Avg Training Time: {benchmark_df['training_time_sec'].mean():.1f}s\n","\n","{'='*80}\n","BEST OVERALL CONFIGURATION\n","{'='*80}\n","\n","Resolution: {overall_best['resolution']}\n","Target: {overall_best['target']}\n","\n","Performance:\n","  MAE:  {overall_best['mae']:.2f}\n","  RMSE: {overall_best['rmse']:.2f}\n","  MAPE: {overall_best['mape']:.2f}%\n","  R¬≤:   {overall_best['r2']:.4f}\n","  Interval Coverage: {overall_best['interval_coverage']:.1f}%\n","\n","Best Hyperparameters:\n","  changepoint_prior_scale: {overall_best['changepoint_prior_scale']}\n","  seasonality_prior_scale: {overall_best['seasonality_prior_scale']}\n","  seasonality_mode: {overall_best['seasonality_mode']}\n","\n","{'='*80}\n","PERFORMANCE BY RESOLUTION\n","{'='*80}\n","\n","\"\"\"\n","\n","for resolution in RESOLUTIONS:\n","    subset = benchmark_df[benchmark_df['resolution'] == resolution]\n","    if len(subset) > 0:\n","        report += f\"\"\"\n","{resolution}:\n","  Average MAE:  {subset['mae'].mean():.2f}\n","  Average MAPE: {subset['mape'].mean():.2f}%\n","  Average R¬≤:   {subset['r2'].mean():.4f}\n","  Best config: {subset.loc[subset['mae'].idxmin(), 'target']} (MAE: {subset['mae'].min():.2f})\n","\"\"\"\n","\n","report += f\"\"\"\n","{'='*80}\n","PERFORMANCE BY TARGET\n","{'='*80}\n","\n","\"\"\"\n","\n","for target in TARGETS:\n","    subset = benchmark_df[benchmark_df['target'] == target]\n","    if len(subset) > 0:\n","        report += f\"\"\"\n","{target}:\n","  Average MAE:  {subset['mae'].mean():.2f}\n","  Average MAPE: {subset['mape'].mean():.2f}%\n","  Average R¬≤:   {subset['r2'].mean():.4f}\n","  Best config: {subset.loc[subset['mae'].idxmin(), 'resolution']} (MAE: {subset['mae'].min():.2f})\n","\"\"\"\n","\n","report += f\"\"\"\n","{'='*80}\n","KEY FINDINGS\n","{'='*80}\n","\n","1. Best Resolution:\n","   - {benchmark_df.groupby('resolution')['mae'].mean().idxmin()} has lowest average MAE ({benchmark_df.groupby('resolution')['mae'].mean().min():.2f})\n","\n","2. Best Target:\n","   - {benchmark_df.groupby('target')['mae'].mean().idxmin()} is easier to predict (MAE: {benchmark_df.groupby('target')['mae'].mean().min():.2f})\n","\n","3. Interval Coverage:\n","   - Average: {benchmark_df['interval_coverage'].mean():.1f}%\n","   - {'Good' if 90 <= benchmark_df['interval_coverage'].mean() <= 98 else 'Needs adjustment'}\n","\n","4. Most Common Best Parameters:\n","   - changepoint_prior_scale: {benchmark_df['changepoint_prior_scale'].mode()[0]}\n","   - seasonality_prior_scale: {benchmark_df['seasonality_prior_scale'].mode()[0]}\n","   - seasonality_mode: {benchmark_df['seasonality_mode'].mode()[0]}\n","\n","{'='*80}\n","RECOMMENDATIONS FOR AUTOSCALING\n","{'='*80}\n","\n","1. Use {overall_best['resolution']} resolution for {overall_best['target']}\n","   - Achieves best accuracy (MAE: {overall_best['mae']:.2f})\n","   - 95% confidence intervals cover {overall_best['interval_coverage']:.1f}% of actuals\n","\n","2. Safety Margins:\n","   - Use upper bound of prediction interval for conservative scaling\n","   - Or use forecast + 2œÉ where œÉ is residual std deviation\n","\n","3. Retraining Strategy:\n","   - Retrain weekly to capture evolving patterns\n","   - Monitor forecast accuracy continuously\n","   - Retrain immediately if MAE increases by >20%\n","\n","4. Production Deployment:\n","   - Load best model parameters from best_parameters.csv\n","   - Use same holiday definitions and regressors\n","   - Validate predictions before scaling actions\n","\n","{'='*80}\n","FILES GENERATED\n","{'='*80}\n","\n","Benchmark Files:\n","  ‚Ä¢ comprehensive_comparison.csv - All metrics for all configurations\n","  ‚Ä¢ benchmark_visualizations.png - Visual comparison\n","  ‚Ä¢ final_report.txt - This report\n","\n","Individual Configuration Results (for each resolution√ótarget):\n","  ‚Ä¢ predictions.csv - Test predictions with confidence intervals\n","  ‚Ä¢ metrics.csv - Performance metrics\n","  ‚Ä¢ best_parameters.csv - Optimal hyperparameters\n","  ‚Ä¢ hyperparameter_tuning.csv - Full tuning results\n","  ‚Ä¢ forecast_full.csv - Complete forecast with components\n","\n","{'='*80}\n","END OF REPORT\n","{'='*80}\n","\"\"\"\n","\n","# Save report\n","report_file = f\"{benchmark_dir}/final_report.txt\"\n","with open(report_file, 'w') as f:\n","    f.write(report)\n","\n","print(report)\n","\n","print(f\"\\n‚úì Final report saved: {report_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"472RsNnIGKhk"},"outputs":[],"source":["# ===========================\n","# CELL 10: SUMMARY & NEXT STEPS\n","# ===========================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"üéâ AUTOMATED PIPELINE COMPLETED SUCCESSFULLY!\")\n","print(\"=\"*80)\n","\n","print(f\"\\nüìä SUMMARY:\")\n","print(f\"  Total configurations trained: {len(all_results)}\")\n","print(f\"  Total time: {total_elapsed/60:.1f} minutes\")\n","print(f\"  Average time per config: {total_elapsed/len(all_results):.1f} seconds\")\n","\n","print(f\"\\nüìÅ RESULTS LOCATION:\")\n","print(f\"  Main directory: {RESULTS_BASE_DIR}\")\n","print(f\"  Benchmark: {benchmark_dir}\")\n","\n","print(f\"\\nüèÜ BEST CONFIGURATION:\")\n","print(f\"  {overall_best['resolution']} | {overall_best['target']}\")\n","print(f\"  MAE: {overall_best['mae']:.2f}, MAPE: {overall_best['mape']:.2f}%, R¬≤: {overall_best['r2']:.4f}\")\n","\n","print(f\"\\nüìà TOP 3 PERFORMERS (by MAE):\")\n","top_3 = benchmark_df.nsmallest(3, 'mae')[['resolution', 'target', 'mae', 'rmse', 'mape']]\n","for idx, row in top_3.iterrows():\n","    print(f\"  {row['resolution']:5s} | {row['target']:15s} | MAE: {row['mae']:6.2f} | MAPE: {row['mape']:5.2f}%\")\n","\n","print(f\"\\nüí° NEXT STEPS:\")\n","print(f\"  1. Review the final_report.txt in {benchmark_dir}\")\n","print(f\"  2. Check benchmark_visualizations.png for visual analysis\")\n","print(f\"  3. Use best_parameters.csv from best configuration for production\")\n","print(f\"  4. Implement Prophet forecasting in autoscaling system\")\n","print(f\"  5. Set up weekly retraining schedule\")\n","\n","print(f\"\\n\" + \"=\"*80)\n","print(\"All results have been saved to Google Drive!\")\n","print(\"=\"*80)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}