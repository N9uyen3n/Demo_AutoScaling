ƒê√¢y l√† m·ªôt b·∫£n thi·∫øt k·∫ø **r·∫•t xu·∫•t s·∫Øc v√† th·ª±c t·∫ø**. B·∫°n ƒë√£ t∆∞ duy ƒë√∫ng h∆∞·ªõng c·ªßa m·ªôt K·ªπ s∆∞ ph·∫ßn m·ªÅm (Software Engineer) thay v√¨ ch·ªâ l√† m·ªôt nh√† khoa h·ªçc d·ªØ li·ªáu (Data Scientist). C·∫•u tr√∫c n√†y t√°ch bi·ªát r√µ r√†ng gi·ªØa **Data**, **Model**, **Core Logic**, v√† **Presentation**, gi√∫p vi·ªác debug v√† m·ªü r·ªông c·ª±c k·ª≥ d·ªÖ d√†ng.

Tuy nhi√™n, ƒë·ªÉ ƒë·∫£m b·∫£o "ƒÉn ƒëi·ªÉm" tuy·ªát ƒë·ªëi theo **Section 8 (Ti√™u ch√≠ ƒë√°nh gi√°)** v√† **Section 3, 5 (Y√™u c·∫ßu k·ªπ thu·∫≠t)** c·ªßa ƒë·ªÅ b√†i, t√¥i xin ph√©p **tinh ch·ªânh nh·∫π** b·∫£n thi·∫øt k·∫ø c·ªßa b·∫°n ƒë·ªÉ n√≥ tr·ªü n√™n ho√†n h·∫£o v√† an to√†n nh·∫•t cho l·ªô tr√¨nh 1 ng√†y.

D∆∞·ªõi ƒë√¢y l√† **B·∫¢N THI·∫æT K·∫æ FINAL (CH·ªêT)**. Ch√∫ng ta s·∫Ω b·∫Øt tay v√†o code ngay sau khi b·∫°n x√°c nh·∫≠n.

---

# üõ†Ô∏è KI·∫æN TR√öC H·ªÜ TH·ªêNG AUTOSCALING (FINAL BLUEPRINT)

### 1. C·∫•u tr√∫c th∆∞ m·ª•c (ƒê√£ tinh ch·ªânh)

*Thay ƒë·ªïi nh·ªè: Th√™m folder `scripts/` ƒë·ªÉ ch·ª©a tool train model/x·ª≠ l√Ω data t√°ch bi·ªát kh·ªèi app ch·∫°y.*

```text
autoscaling-analysis/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ processed/                    # CSV ch·ª©a 3 c·ªôt: timestamp, requests, bytes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ traffic_1m.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ traffic_5m.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ traffic_15m.csv
‚îÇ   ‚îî‚îÄ‚îÄ models/                       # Models (.keras, .joblib) & Scalers (.pkl)
‚îÇ       ‚îú‚îÄ‚îÄ lstm/
‚îÇ       ‚îî‚îÄ‚îÄ prophet/ (ho·∫∑c xgboost)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py                     # CONFIGURATION CENTER (Quan tr·ªçng)
‚îÇ   ‚îú‚îÄ‚îÄ app.py                        # Streamlit Dashboard (Presentation Layer)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                         # BUSINESS LOGIC LAYER
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoscaler.py             # Logic Scaling (CPU, Cooldown, Hysteresis)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ anomaly.py                # Logic DDoS Detection
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ engine/                       # AI/MODEL LAYER
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictor_factory.py      # Factory Pattern ƒë·ªÉ g·ªçi model (LSTM/Prophet)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ loader.py                 # Class load model & scaler an to√†n
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                        # UTILITIES
‚îÇ       ‚îú‚îÄ‚îÄ data_processing.py        # H√†m ƒë·ªçc CSV, resample log th√¥ (n·∫øu c·∫ßn)
‚îÇ       ‚îî‚îÄ‚îÄ simulation.py             # Class qu·∫£n l√Ω Replay Loop (quan tr·ªçng cho Demo)
‚îÇ
‚îú‚îÄ‚îÄ api/                              # API LAYER (ƒê·ªÉ tho·∫£ m√£n Section 5 & 8)
‚îÇ   ‚îî‚îÄ‚îÄ main.py                       # FastAPI (Wrapper g·ªçi src.core & src.engine)
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md                         # T√†i li·ªáu (B·∫Øt bu·ªôc)
‚îî‚îÄ‚îÄ run_demo.sh                       # Script 1 ch·∫°m ƒë·ªÉ ch·∫°y App

```

---

### 2. Chi ti·∫øt tri·ªÉn khai t·ª´ng Module (Theo th·ª© t·ª± ∆∞u ti√™n)

T√¥i s·∫Øp x·∫øp l·∫°i th·ª© t·ª± code ƒë·ªÉ b·∫°n c√≥ "S·∫£n ph·∫©m ch·∫°y ƒë∆∞·ª£c" (MVP) nhanh nh·∫•t.

#### ü•á Phase 1: The Core (Logic nghi·ªáp v·ª• - Kh√¥ng ph·ª• thu·ªôc Model)

Ch√∫ng ta code ph·∫ßn n√†y tr∆∞·ªõc v√¨ n√≥ thu·∫ßn Python, d·ªÖ test, v√† l√† ph·∫ßn "Engineering" gi√°m kh·∫£o soi k·ªπ.

1. **`src/config.py`**: N∆°i ch·ª©a m·ªçi tham s·ªë.
* *T·∫°i sao:* Gi√°m kh·∫£o h·ªèi "N·∫øu ƒë·ªïi server ch·ªãu t·∫£i 2000 req th√¨ sao?", b·∫°n ch·ªâ c·∫ßn s·ª≠a file n√†y, kh√¥ng s·ª≠a code.


2. **`src/core/autoscaler.py`**:
* Input: `current_load`, `forecast_load`.
* Logic:
* `Raw Scale`: `ceil(load / capacity)`.
* `Cooldown`: D√πng bi·∫øn ƒë·∫øm (counter) ƒë·ªÉ block scale-down ngay sau khi scale-up.
* `Safety`: Lu√¥n gi·ªØ `min_servers`.


* Output: `num_servers`, `reason`, `cost`.



#### ü•à Phase 2: The Simulation (H·ªá th·ªëng gi·∫£ l·∫≠p)

Tr∆∞·ªõc khi l·∫Øp AI v√†o, h·ªá th·ªëng ph·∫£i ch·∫°y ƒë∆∞·ª£c b·∫±ng d·ªØ li·ªáu gi·∫£ ho·∫∑c d·ªØ li·ªáu file CSV thu·∫ßn t√∫y.

1. **`src/utils/simulation.py`**:
* Class `TimeTraveler`: ƒê·ªçc file CSV, h√†m `next_tick()` tr·∫£ v·ªÅ d·ªØ li·ªáu ph√∫t ti·∫øp theo.
* Gi√∫p Dashboard c√≥ hi·ªáu ·ª©ng ch·∫°y theo th·ªùi gian th·ª±c.



#### ü•â Phase 3: The AI Integration (L·∫Øp n√£o v√†o)

ƒê√¢y l√† l√∫c load file `.keras` v√† `.pkl`.

1. **`src/engine/loader.py`**:
* Load Keras Model + Joblib Scaler.
* *Quan tr·ªçng:* X·ª≠ l√Ω l·ªói "File not found" -> N·∫øu kh√¥ng c√≥ model, t·ª± ƒë·ªông fallback v·ªÅ thu·∫≠t to√°n Naive (d·ª± b√°o = hi·ªán t·∫°i) ƒë·ªÉ demo kh√¥ng b·ªã crash.


2. **`src/engine/predictor_factory.py`**:
* H√†m `predict(history_window)`:
* Chu·∫©n h√≥a `history_window` b·∫±ng Scaler.
* Reshape `(1, 30, 1)`.
* G·ªçi `model.predict`.
* Inverse transform k·∫øt qu·∫£.





#### üèÖ Phase 4: The Interface (Streamlit & API)

Cu·ªëi c√πng l√† v·∫Ω giao di·ªán.

1. **`src/app.py`**:
* Giao di·ªán 2 c·ªôt: B√™n tr√°i Control (Start/Stop, Speed), B√™n ph·∫£i Dashboard.
* Bi·ªÉu ƒë·ªì Plotly c·∫≠p nh·∫≠t ƒë·ªông.


2. **`api/main.py`**:
* Vi·∫øt ƒë√∫ng 2 endpoint `/forecast` v√† `/recommend` g·ªçi v√†o h√†m trong `src/core` v√† `src/engine`. (Ch·ªâ m·∫•t 15 ph√∫t code).



---

### 3. Tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa b·∫°n

1. **B·∫°n ƒë√£ c√≥ model LSTM ch∆∞a?**
* *ƒê√°p:* B·∫°n ƒë√£ upload file `lstm-bilstm-training.ipynb`. T√¥i gi·∫£ ƒë·ªãnh b·∫°n ƒë√£ ch·∫°y n√≥ v√† c√≥ file `.keras`. **N·∫øu ch∆∞a, t√¥i s·∫Ω cung c·∫•p m·ªôt script `generate_dummy_model.py` t·∫°o m·ªôt model "gi·∫£" (random weight ho·∫∑c simple regression) ƒë·ªÉ b·∫°n code xong h·ªá th·ªëng tr∆∞·ªõc, r·ªìi train model x·ªãn l·∫Øp v√†o sau.** -> *Chi·∫øn thu·∫≠t n√†y gi√∫p b·∫°n kh√¥ng b·ªã t·∫Øc ·ªü kh√¢u train.*


2. **Prophet hay LSTM?**
* *ƒê√°p:* **LSTM l√† ch√≠nh (Must Have)** v√¨ b·∫°n ƒë√£ c√≥ code train. Prophet l√† ph·ª•. Trong code t√¥i s·∫Ω ƒë·ªÉ s·∫µn ch·ªó cho Prophet, n·∫øu c√≤n th·ªùi gian (sau khi app ch·∫°y ngon), ta ch·ªâ c·∫ßn train Prophet 10 ph√∫t v√† b·ªè file v√†o l√† xong.


3. **D·ªØ li·ªáu Aggregate?**
* *ƒê√°p:* T√¥i s·∫Ω vi·∫øt cho b·∫°n script `src/utils/etl.py` ƒë·ªÉ convert log NASA g·ªëc -> CSV 1m/5m/15m ngay l·∫≠p t·ª©c. ƒê√¢y l√† b∆∞·ªõc ƒë·∫ßu ti√™n ph·∫£i l√†m.


4. **API c√≥ c·∫ßn kh√¥ng?**
* *ƒê√°p:* **C√ì**. Trong file ƒë·ªÅ b√†i m·ª•c 8 (N·ªôp b√†i) ghi: "Demo: API... HO·∫∂C UI". Tuy nhi√™n m·ª•c 5 ghi "Tri·ªÉn khai API". ƒê·ªÉ an to√†n tuy·ªát ƒë·ªëi v√† th·ªÉ hi·ªán tr√¨nh ƒë·ªô, ch√∫ng ta s·∫Ω code UI Streamlit l√† ch√≠nh, nh∆∞ng k√®m file `api/main.py` (FastAPI) ƒë∆°n gi·∫£n. Code FastAPI d√πng chung logic v·ªõi Streamlit n√™n r·∫•t nhanh.



---

### 4. K·∫ø ho·∫°ch h√†nh ƒë·ªông ngay b√¢y gi·ªù

B·∫°n ƒë√£ ƒë·ªìng √Ω v·ªõi h∆∞·ªõng ƒëi n√†y ch∆∞a? N·∫øu **OK**, t√¥i s·∫Ω b·∫Øt ƒë·∫ßu cung c·∫•p code theo tr√¨nh t·ª± sau:

1. **G√≥i 1 (N·ªÅn t·∫£ng):** `requirements.txt`, `src/config.py`, v√† `src/utils/etl.py` (ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu ngay).
2. **G√≥i 2 (Logic):** `src/core/autoscaler.py` v√† `src/core/anomaly.py`.
3. **G√≥i 3 (AI Engine):** Class wrapper cho LSTM.
4. **G√≥i 4 (UI):** `src/app.py` ho√†n ch·ªânh.

B·∫°n mu·ªën t√¥i b·∫Øt ƒë·∫ßu **G√≥i 1** ngay kh√¥ng?
---
###  SESSION LOG [2026-02-02]

** Done:**
1.  **Restructured Project**: Moved to modular architecture (src/core, src/engine, src/utils).
2.  **Implemented Core Logic**: Autoscaler (Cooldown, Safety) & Anomaly Detection.
3.  **Expanded AI Engine**: Added support for **LSTM**, **ARIMA**, **Prophet**, and **Hybrid** models.
4.  **Enhanced Dashboard**:
    *   Added **Model Selector** (LSTM/ARIMA/Prophet/Hybrid).
    *   Added **Resolution Selector** (1m/5m/15m).
    *   Implemented smooth fallback (synthetic data) if real data/models are missing.
5.  **Dependencies**: Installed successfully via pip install -r ../requirements.txt.

** Pending / Next Steps:**
1.  **Generate Dummy Models**: The script scripts/generate_dummy_model.py failed due to missing 
umpy in the execution environment (despite being installed).
    *   *Action*: Re-run this script in the correct environment or fix imports.
2.  **Run Demo**: Execute un_demo.bat to verify the end-to-end flow.
3.  **Train Real Models**: Replace dummy .h5 and .pkl files with actual trained models from the notebooks.

** To Resume:**
Run python scripts/generate_dummy_model.py then un_demo.bat.
