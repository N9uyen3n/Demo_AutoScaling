# PLANORA Module Structure Documentation

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
AUTOSCALING ANALYSIS/
â”œâ”€â”€ app.py                          # Main entry point (NEW - modular version)
â”œâ”€â”€ test.py                         # Original monolithic version (backup)
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                 # Configuration constants
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ai_models.py                # AI prediction logic
â”‚   â”œâ”€â”€ scaling_logic.py            # Autoscaling decisions
â”‚   â”œâ”€â”€ data_loader.py              # Load & validate data (NEW)
â”‚   â””â”€â”€ model_manager.py            # Load/save ML models (NEW)
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sidebar.py                  # Sidebar UI
â”‚   â”œâ”€â”€ metrics.py                  # KPI cards
â”‚   â”œâ”€â”€ charts.py                   # Plotly charts
â”‚   â”œâ”€â”€ tabs.py                     # Analysis tabs
â”‚   â””â”€â”€ production_mode.py          # Production mode controls (NEW)
â”‚
â”œâ”€â”€ styles/
â”‚   â””â”€â”€ aws_theme.py                # AWS CSS theme
â”‚
â”œâ”€â”€ DATA/
â”‚   â””â”€â”€ sample_data.csv             # Sample CSV data (NEW)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ README.md                   # Model documentation (NEW)
â”‚   â””â”€â”€ (your trained models here)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ¯ Chá»©c nÄƒng tá»«ng module

### ğŸ“¦ config/settings.py

**Má»¥c Ä‘Ã­ch**: Centralize táº¥t cáº£ configuration constants

**Ná»™i dung**:
- AWS color palette
- Default thresholds (scale-out, scale-in, cooldown)
- Simulation parameters
- Chart configurations
- Anomaly detection thresholds

**Sá»­ dá»¥ng**:
```python
from config.settings import AWS_ORANGE, DEFAULT_SCALE_OUT_THRESHOLD
```

---

### ğŸ¤– utils/ai_models.py

**Má»¥c Ä‘Ã­ch**: AI prediction vÃ  anomaly detection logic

**Functions**:
- `get_ai_prediction_multi_horizon(current_load, iteration)` - Dá»± bÃ¡o 1m, 5m, 15m
- `detect_anomaly(actual_load, forecast_1m)` - PhÃ¡t hiá»‡n DDoS/spike
- `generate_simulated_load(iteration)` - Táº¡o táº£i giáº£ láº­p

**Placeholder cho model tháº­t**:
```python
# CHá»– TRá»NG Äá»‚ Láº®P MODEL:
predictions = model.predict(features, horizons=[1,5,15])
```

---

### âš™ï¸ utils/scaling_logic.py

**Má»¥c Ä‘Ã­ch**: Autoscaling decision logic

**Functions**:
- `scaling_logic(forecast_5m, actual_load, session_state, ...)` - Quyáº¿t Ä‘á»‹nh scale up/down
- `calculate_cpu_utilization(actual_load, replicas)` - TÃ­nh CPU %
- `calculate_cost_savings(total_cost_ai, total_cost_fixed)` - TÃ­nh tiáº¿t kiá»‡m

---

### ğŸ“Š utils/data_loader.py (NEW)

**Má»¥c Ä‘Ã­ch**: Load vÃ  validate dá»¯ liá»‡u tá»« nhiá»u nguá»“n

**Classes**:
- `DataLoader`:
  - `load_from_csv(file_path)` - Load tá»« CSV file
  - `load_from_uploaded_file(uploaded_file)` - Load tá»« Streamlit upload
  - `validate_data(df)` - Validate data format
  - `generate_sample_data(num_points)` - Táº¡o sample data

- `DataPreprocessor`:
  - `extract_features(df)` - Extract time features (hour, day_of_week, etc.)
  - `create_lag_features(df, target_col, lags)` - Táº¡o lag features

**Sá»­ dá»¥ng**:
```python
from utils import DataLoader

# Load CSV
df = DataLoader.load_from_csv('DATA/sample_data.csv')

# Validate
validation = DataLoader.validate_data(df)
if validation['is_valid']:
    print("âœ… Data valid!")
```

---

### ğŸ§  utils/model_manager.py (NEW)

**Má»¥c Ä‘Ã­ch**: Quáº£n lÃ½ ML models (load, save, predict)

**Classes**:
- `ModelManager`:
  - `load_model(model_path)` - Load model tá»« .pkl/.joblib
  - `save_model(model, model_name, format)` - Save model
  - `predict_multi_horizon(features, horizons)` - Dá»± bÃ¡o Ä‘a thá»i Ä‘iá»ƒm
  - `get_model_info()` - Láº¥y thÃ´ng tin model

- `ModelTrainer`:
  - `train_xgboost(X_train, y_train, params)` - Train XGBoost
  - `train_arima(data, order)` - Train ARIMA

**Sá»­ dá»¥ng**:
```python
from utils import ModelManager

# Load model
manager = ModelManager()
manager.load_model('models/xgboost_model.joblib')

# Predict
predictions = manager.predict_multi_horizon(features, horizons=[1,5,15])
```

---

### ğŸ¨ components/sidebar.py

**Má»¥c Ä‘Ã­ch**: Render sidebar controls

**Functions**:
- `render_sidebar()` - Render sidebar, return settings dict

**Returns**:
```python
{
    'sim_speed': 0.5,
    'threshold_up': 150,
    'threshold_down': 50,
    'cooldown': 3,
    'model_type': 'XGBoost (Simulated)'
}
```

---

### ğŸ“ˆ components/metrics.py

**Má»¥c Ä‘Ã­ch**: KPI metric cards

**Functions**:
- `create_kpi_placeholders()` - Táº¡o 6 placeholder objects
- `render_kpi_cards(placeholders, data, history)` - Update KPI values

---

### ğŸ“Š components/charts.py

**Má»¥c Ä‘Ã­ch**: Plotly chart creation

**Functions**:
- `create_traffic_chart(history, threshold_up, threshold_down)` - Main traffic chart
- `create_resource_gauge(cpu_util)` - CPU gauge
- `create_error_distribution(predictions_history)` - Error histogram

---

### ğŸ“‹ components/tabs.py

**Má»¥c Ä‘Ã­ch**: Analysis tabs rendering

**Functions**:
- `render_scaling_events_tab(history, placeholder)` - Tab 1
- `render_model_performance_tab(predictions_history, placeholder, iteration)` - Tab 2
- `render_security_tab(history, is_anomaly, anomaly_msg, placeholder)` - Tab 3

---

### ğŸ¯ components/production_mode.py (NEW)

**Má»¥c Ä‘Ã­ch**: Production mode UI controls

**Functions**:
- `render_production_mode_controls()` - Render mode selection UI
- `render_data_info(df)` - Display data information
- `render_model_info(model_manager)` - Display model information

**Returns**:
```python
{
    'mode': 'Production (Real Data)',
    'data_source': 'Upload CSV',
    'model_path': 'models/xgboost_model.joblib',
    'uploaded_data': <UploadedFile>
}
```

---

### ğŸ¨ styles/aws_theme.py

**Má»¥c Ä‘Ã­ch**: AWS CSS styling

**Functions**:
- `get_aws_css()` - Return complete AWS CSS string

---

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### Mode 1: Simulation (Default)

```bash
streamlit run app.py
```

- Sidebar: Äá»ƒ mode máº·c Ä‘á»‹nh "Simulation"
- Dá»¯ liá»‡u: Tá»± Ä‘á»™ng generate theo hÃ m sin
- AI: Sá»­ dá»¥ng simulation logic

### Mode 2: Production vá»›i Real Data

1. **Chuáº©n bá»‹ dá»¯ liá»‡u CSV**:
   ```csv
   timestamp,requests_per_minute
   2026-01-23 00:00:00,85
   2026-01-23 00:01:00,92
   ...
   ```

2. **Cháº¡y app**:
   ```bash
   streamlit run app.py
   ```

3. **Trong sidebar**:
   - Chá»n "Production (Real Data)"
   - Data Source: "Upload CSV" hoáº·c "Load from File"
   - Upload file hoáº·c nháº­p path: `DATA/sample_data.csv`

### Mode 3: Production vá»›i Trained Model

1. **Train model** (vÃ­ dá»¥ XGBoost):
   ```python
   import xgboost as xgb
   import joblib
   
   # Train
   model = xgb.XGBRegressor(max_depth=6, learning_rate=0.1)
   model.fit(X_train, y_train)
   
   # Save
   joblib.dump(model, 'models/xgboost_model.joblib')
   ```

2. **Trong sidebar**:
   - Chá»n "Production (Real Data)"
   - Check "Use Trained Model"
   - Model Path: `models/xgboost_model.joblib`

---

## ğŸ“ So sÃ¡nh test.py vs app.py

| Aspect | test.py (Old) | app.py (New) |
|--------|---------------|--------------|
| **Lines of Code** | 532 dÃ²ng | ~230 dÃ²ng |
| **Structure** | Monolithic | Modular |
| **Maintainability** | KhÃ³ | Dá»… |
| **Testability** | KhÃ³ unit test | Dá»… unit test |
| **Reusability** | KhÃ´ng | Cao |
| **Production Ready** | KhÃ´ng | CÃ³ |
| **Data Source** | Chá»‰ simulation | CSV, Upload, API |
| **Model Support** | KhÃ´ng | XGBoost, ARIMA, etc. |

---

## ğŸ“ Best Practices

### 1. ThÃªm model má»›i

Táº¡o file trong `utils/model_manager.py`:
```python
@staticmethod
def train_lstm(data, params):
    # Your LSTM training logic
    pass
```

### 2. ThÃªm data source má»›i

Táº¡o method trong `utils/data_loader.py`:
```python
@staticmethod
def load_from_api(api_url):
    # Your API loading logic
    pass
```

### 3. ThÃªm chart má»›i

Táº¡o function trong `components/charts.py`:
```python
def create_custom_chart(data):
    # Your chart logic
    return fig
```

---

## ğŸ› Troubleshooting

### Error: "Module not found"
```bash
# Ensure you're in the right directory
cd "d:\Study\Year4\ki2\AUTOSCALING ANALYSIS"

# Activate venv
.venv\Scripts\Activate.ps1
```

### Error: "Model file not found"
- Check path trong sidebar
- Ensure model file exists trong `models/` folder

### Error: "Invalid CSV format"
- Check CSV cÃ³ columns: `timestamp`, `requests_per_minute`
- Timestamp format: `YYYY-MM-DD HH:MM:SS`

---

**Made with â¤ï¸ for modular, scalable, production-ready applications**
